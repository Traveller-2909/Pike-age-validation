---
title: "Analysis pike age corroboration"
author: "TR"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**All code chunks except for figures used in the publication have "eval=FALSE" set in options, to avoid running the whole script every time a document is knitted. In order to run an individual code chunk, change options "eval=FALSE" to "eval=TRUE"**

```{r packages, include=FALSE}
library(here)
library(ggplot2)
library(tidyverse)
library(foreign)
library(lubridate)
library(car)
library(FSA)
library(flextable)
library(lme4)
library(ggpubr)
library(tidymodels)
library(nlstools)
library(bayesplot)
library(RColorBrewer)
library(loo)
library("rstan")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(sjPlot)
```

## 3.1. Expected $\delta^{18}$O values in otolith aragonite
```{r prediction of otolith d18O, include=FALSE, eval=FALSE}
rm(list = ls())

source("Interpolation_function.R")

#Get isotope data
Isotopes <- fread("Data/Water_isotopes_Bodden.txt")

LUNGdata <- read.delim(file = "Data/LUNGdata_complete.txt", sep = "\t", header = T, stringsAsFactors = F)
LUNGdata_Bodden <- LUNGdata%>%
  filter(type=="Coast")%>%
  mutate(area=case_when(waterbody=="Kubitzer Bodden"~"WRB",
                        waterbody=="Greifswalder Bodden"~"GB",
                        waterbody=="Daenische Wiek"~"GB",
                        waterbody=="Andershofer Bucht"~"GB",
                        waterbody=="Vitter Bodden"~"WRB",
                        waterbody=="Rassower Strom"~"NRB",
                        waterbody=="Breetzer Bodden"~"NRB",
                        waterbody=="Gr. Jasmunder Bodden"~"NRB",
                        waterbody=="Kl. Jasmunder Bodden"~"NRB",
                        waterbody=="Schaproder Bodden"~"WRB",
                        TRUE~"NA"))%>%
  filter(area!="NA")

Lungdata_fresh <- LUNGdata%>%
  filter(type=="Freshwater")%>%
  mutate(area=case_when(waterbody=="Barthe"~"Tributary",
                        waterbody=="Westziese"~"Tributary",
                        waterbody=="Ostziese"~"Tributary",
                        waterbody=="Sehrower Bach"~"Tributary",
                        waterbody=="Badendycksgraben"~"Tributary",
                        TRUE~"NA"))

Bodden_mean <- LUNGdata_Bodden%>%
  group_by(area, year, month)%>%
  dplyr::summarise(area=area,
                   year=year,
                   type=type,
                   SAL=mean(SAL, na.rm=T),
                   WT=mean(WT, na.rm=T))%>%
  distinct()

Fresh_mean <- Lungdata_fresh%>%
  filter(area!="NA")%>%
  group_by(area, year, month)%>%
  dplyr::summarise(area=area,
                   year=year,
                   type=type,
                   SAL=mean(SAL, na.rm=T),
                   WT=mean(WT, na.rm=T))%>%
  distinct()

Isotopes2 <- Isotopes%>%
  transmute(waterbody=waterbody,
            month=month(parse_date_time(Date, "dmy")),
            area=case_when(waterbody=="Uck"~"NA",
                           waterbody=="SH"~"SH",
                           waterbody=="Peene"~"Tributary",
                           waterbody=="P"~"P",
                           waterbody=="AW"~"P",
                           waterbody=="GB"~"GB",
                           waterbody=="Ryck"~"NA",
                           waterbody=="S"~"WRB",
                           waterbody=="Beek"~"NA",
                           waterbody=="GJB"~"NRB",
                           waterbody=="KJB"~"NRB",
                           waterbody=="Baltic"~"Baltic",
                           waterbody=="BEG"~"NRB",
                           waterbody=="WB"~"NRB",
                           waterbody=="VB"~"WRB",
                           waterbody=="SB"~"WRB",
                           waterbody=="KB"~"WRB",
                           waterbody=="GW"~"DZB",
                           waterbody=="BAT"~"DZB",
                           waterbody=="Barthe"~"Tributary",
                           waterbody=="BoB"~"DZB",
                           waterbody=="SaB"~"SaB",
                           waterbody=="Templer creek"~"NA",
                           waterbody=="Recknitz"~"NA",
                           waterbody=="ZS"~"ZS"),
            coast.FW=`coast/FW`,
            d18O=d18O,
            Sal=Sal_PSU,
            WT=WT_C)%>%
  drop_na(d18O)

Isotopes_mean <- Isotopes2%>%
  group_by(month, area)%>%
  dplyr::summarise(month=month,
                   area=area,
                   coast.FW=coast.FW,
                   d18O=mean(d18O, na.rm=T),
                   Sal=mean(Sal, na.rm=T),
                   WT=mean(WT, na.rm=T))%>%
  distinct()

subset.WRB <- subset(Isotopes_mean, area=="WRB")
subset.fresh <- subset(Isotopes_mean, area=="ZS")


#data frame for merging
df <- data.frame(month = 1:12)

#get data for NRB
subset.NRB <- subset(Isotopes_mean, area=="NRB")
#complete months
subset.NRB <- merge(df, subset.NRB, by = "month", all.x = T)
#interpolate between months
subset.NRB$d18O <- na.approx(subset.NRB$d18O, na.rm=F)

#apply linear correction of missing values based on seasonal offset from timeseries
subset.NRB$d18O[1:2] <- subset.WRB$d18O[1:2]/subset.WRB$d18O[3]*subset.NRB$d18O[3]
subset.NRB$d18O[8:12] <- subset.WRB$d18O[8:12]/subset.WRB$d18O[7]*subset.NRB$d18O[7]
subset.NRB$area <- "NRB"

#same for GB area
subset.GB <- subset(Isotopes_mean, area=="GB")
subset.GB <- merge(df, subset.GB, by="month", all.x = T)
subset.GB$d18O <- na.approx(subset.GB$d18O, na.rm=F)

#apply linear correction of missing values based on seasonal offset from timeseries
subset.GB$d18O[1:2] <- subset.WRB$d18O[1:2]/subset.WRB$d18O[3]*subset.GB$d18O[3]
subset.GB$d18O[8:12] <- subset.WRB$d18O[8:12]/subset.WRB$d18O[7]*subset.GB$d18O[7]
subset.GB$area <- "GB"

#tributaries
subset.tributary <- subset(Isotopes_mean, area == "Tributary")
subset.tributary <- merge(df, subset.tributary, by="month", all.x = T)
subset.tributary$d18O <- na.approx(subset.tributary$d18O, na.rm=F)

#apply linear correction of missing values based on seasonal offset from timeseries
subset.tributary$d18O[1:2] <- subset.fresh$d18O[1:2]/subset.fresh$d18O[3]*subset.tributary$d18O[3]
subset.tributary$d18O[8:12] <- subset.fresh$d18O[8:12]/subset.fresh$d18O[7]*subset.tributary$d18O[7]
subset.tributary$area <- "Tributary"

Bodden_iso <- rbind(subset.GB[,c(1,2,4)],subset.WRB[,c(1,2,4)],subset.NRB[,c(1,2,4)])

Fresh_iso <- subset.tributary[,c(1,2,4)]

Bodden_iso_temp <- Bodden_mean%>%left_join(Bodden_iso, by=c("month", "area"))
Fresh_iso_temp <- Fresh_mean%>%left_join(Fresh_iso, by=c("month", "area"))


#Fractionation equation for otolith aragonite
Patterson <- function(month, WT, d18O){
  alpha <- exp((18.56*1000*((WT+273.15)^-1)-33.49)/1000)
  0.97001*(alpha*(1000+d18O)-1000)-29.99
}

Geffen <- function(month, WT, d18O){
  alpha <- exp((15.99*1000*((WT+273.15)^-1)-24.25)/1000)
  0.97001*(alpha*(1000+d18O)-1000)-29.99
}

#calculate theoretical otolith d18O values with prediction intervals
Bodden_iso_oto <- Bodden_iso_temp%>%
  mutate(d18O.oto.Patterson = Patterson(month,WT,d18O),
         d18O.oto.Geffen = Geffen(month,WT,d18O),
         date=as.Date(paste0(year,"-",month,"-","01")))%>%
  group_by(month, year)%>%
  mutate(upper.Pat=max(d18O.oto.Patterson),
         lower.Pat=min(d18O.oto.Patterson),
         upper.Gef=max(d18O.oto.Geffen),
         lower.Gef=min(d18O.oto.Geffen))

Fresh_iso_oto <- Fresh_iso_temp%>%
  mutate(d18O.oto.Patterson = Patterson(month,WT,d18O),
         d18O.oto.Geffen = Geffen(month,WT,d18O),
         date=as.Date(paste0(year,"-",month,"-","01")))%>%
  group_by(month)%>%
  mutate(upper.Pat=max(d18O.oto.Patterson),
         lower.Pat=min(d18O.oto.Patterson),
         upper.Gef=max(d18O.oto.Geffen),
         lower.Gef=min(d18O.oto.Geffen))

fwrite(Bodden_iso_oto, "Data/Bodden_iso_prediction.csv")
fwrite(Fresh_iso_oto, "Data/Tributary_iso_prediction.csv")
```

```{r interpolate observed otolith values, include=FALSE, eval=FALSE}
rm(list = ls())

#Get pike data
Pike <- fread("Data/Pike-d18O-years_whole-sample_with-TL.txt")

Pike2 <- Pike%>%
  filter(area!="KD")%>%
  group_by(fishID)%>%
  mutate(lifeyear2 = cohort+lifeyear)%>%
  drop_na(d18O)

#subset pike according to lifeyears as read
Pike.1 <- subset(Pike2[Pike2$age>=1,], lifeyear==1)
Pike.2 <- subset(Pike2[Pike2$age>=2,], lifeyear==2)
Pike.3 <- subset(Pike2[Pike2$age>=3,], lifeyear==3)
Pike.4 <- subset(Pike2[Pike2$age>=4,], lifeyear==4)
Pike.5 <- subset(Pike2[Pike2$age>=5,], lifeyear==5)
Pike.6 <- subset(Pike2[Pike2$age>=6,], lifeyear==6)
Pike.7 <- subset(Pike2[Pike2$age>=7,], lifeyear==7)
Pike.8 <- subset(Pike2[Pike2$age>=8,], lifeyear==8)
Pike.9 <- subset(Pike2[Pike2$age>=9,], lifeyear==9)
Pike.10 <- subset(Pike2[Pike2$age>=10,], lifeyear==10)

Pike_year1 <- interpol(series = Pike.1, length = 12, element = "d18O")
Pike_year2 <- interpol(series = Pike.2, length = 12, element = "d18O")
Pike_year3 <- interpol(series = Pike.3, length = 12, element = "d18O")
Pike_year4 <- interpol(series = Pike.4, length = 12, element = "d18O")
Pike_year5 <- interpol(series = Pike.5, length = 12, element = "d18O")
Pike_year6 <- interpol(series = Pike.6, length = 12, element = "d18O")
Pike_year7 <- interpol(series = Pike.7, length = 12, element = "d18O")
Pike_year8 <- interpol(series = Pike.8, length = 12, element = "d18O")
Pike_year9 <- interpol(series = Pike.9, length = 12, element = "d18O")
Pike_year10 <- interpol(series = Pike.10, length = 12, element = "d18O")

Pike_year1$lifeyear <- 1
Pike_year2$lifeyear <- 2
Pike_year3$lifeyear <- 3
Pike_year4$lifeyear <- 4
Pike_year5$lifeyear <- 5
Pike_year6$lifeyear <- 6
Pike_year7$lifeyear <- 7
Pike_year8$lifeyear <- 8
Pike_year9$lifeyear <- 9
Pike_year10$lifeyear <- 10

Pikeyears <- rbind(Pike_year1, Pike_year2, Pike_year3, Pike_year4, Pike_year5, Pike_year6, Pike_year7, Pike_year8, Pike_year9, Pike_year10)

Pikeyears2 <- Pike2%>%
  filter(comment!="Vaterite")%>%
  inner_join(Pikeyears, by = c("fishID", "lifeyear"))%>%
  transmute(fishID=fishID,
            capt_date=capt_date,
            area=case_when(area=="Peene"~"Tributary",
                           area=="Barthe"~"Tributary",
                           area=="SB"~"WRB",
                           area=="WB"~"NRB",
                           area=="KB"~"WRB",
                           area=="GB"~"GB",
                           area=="BEG"~"NRB",
                           area=="KJB"~"NRB",
                           area=="GJB"~"NRB",
                           area=="NHG"~"Tributary",
                           area=="Sehrowbach"~"Tributary",
                           area=="Badendycksgraben"~"Tributary",
                           area=="Ziese"~"Tributary"),
            age=age,
            cohort=cohort,
            lifeyear=lifeyear,
            month=month,
            year=lifeyear2,
            d18O=value,
            date=as.Date(paste0(year,"-",month,"-","01")))%>%
  distinct()

Pikeyears3 <- Pikeyears2%>%
  group_by(area, date)%>%
  summarise(cohort=cohort,
            month=month,
            d18O=mean(d18O))%>%
  distinct()

fwrite(Pikeyears2, "Data/Pike_d18O_indiv_years_interpolated.csv")
fwrite(Pikeyears3, "Data/Pike_d18O_mean-area_years_interpolated.csv")
```

```{r d18O modelling figures, include=FALSE, eval=FALSE}
rm(list = ls())

#Read in data
Pikeyears2 <- fread("Data/Pike_d18O_indiv_years_interpolated.csv")
Pikeyears3 <- fread("Data/Pike_d18O_mean-area_years_interpolated.csv")
Bodden_iso_oto <- fread("Data/Bodden_iso_prediction.csv")
Fresh_iso_oto <- fread("Data/Tributary_iso_prediction.csv")

#Plot temperature data
Temperature <- ggplot()+
  geom_line(data = Bodden_iso_oto, aes(x = date, y = WT, color=area), size = 1)+
  geom_line(data = Fresh_iso_oto, aes(x = date, y = WT, color=area), size = 1)+
  geom_vline(xintercept = as.Date(c("2008-12-01","2009-12-01","2010-12-01","2011-12-01","2012-12-01","2013-12-01","2014-12-01","2015-12-01",
                          "2016-12-01","2017-12-01","2018-12-01","2019-12-01","2020-12-01","2021-12-01","2022-12-01")), alpha = .5,
             linetype = "dotted")+
  scale_fill_manual(breaks = c("Lagoon", "Tributary"), 
                     values = c("#7570B3","#66A61E"), 
                     labels = c("Lagoon prediction", "Tributary prediction"))+
  scale_color_manual(breaks = c("GB", "NRB", "Tributary", "WRB"),
                     values = c("#C5D86D","#AF3800","#00BFB2","#004643"))+
  scale_x_date(breaks = as.Date(c("2008-01-01","2009-01-01","2010-01-01","2011-01-01","2012-01-01","2013-01-01","2014-01-01","2015-01-01",
                          "2016-01-01","2017-01-01","2018-01-01","2019-01-01","2020-01-01","2021-01-01","2022-01-01")),
               labels = c(as.character(c(2008:2022))),
               limits = c(min(Pikeyears2$date), max(Pikeyears2$date)))+
  labs(y = "Water temperature (Â°C)",
       color = "area: ")+
  theme_classic()+theme(panel.grid.major.y = element_line(size = .3),
        panel.border = element_rect(fill = NA, size = .3),
        plot.margin = margin(c(20,10,1,1)),
        axis.text.x = element_text(color = "transparent", size = 15, angle = 90),
        axis.text.y = element_text(color = "black", size = 15),
        axis.ticks.x = element_line(colour = "transparent"),
        axis.ticks.y = element_line(size = 0.3),
        axis.ticks.length.y = unit(0.05, "cm"),
        axis.title.x = element_text(size = 15, color = "transparent"),
        axis.title.y = element_text(size = 15, color = "black"),
        axis.line = element_line(size = 0.3),
        legend.text = element_text(size = 15, color = "black"),
        legend.title = element_text(size = 15, color = "black"),
        legend.position = "bottom")

#Plot water isotope data and predicted intervals
Isotopes <- ggplot()+
  geom_line(data = Bodden_iso_oto, aes(x = date, y = d18O, color="d18O"), size = 1)+
  geom_ribbon(data = Bodden_iso_oto, aes(x = date, ymin = lower.Pat, ymax = upper.Pat, fill = "Lagoon"), alpha = 0.3)+
  geom_ribbon(data = Bodden_iso_oto, aes(x = date, ymin = lower.Gef, ymax = upper.Gef, fill = "Lagoon"), alpha = 0.3)+
  geom_ribbon(data = Fresh_iso_oto, aes(x = date, ymin = lower.Pat, ymax = upper.Pat, fill = "Tributary"), alpha = 0.3)+
  geom_ribbon(data = Fresh_iso_oto, aes(x = date, ymin = lower.Gef, ymax = upper.Gef, fill = "Tributary"), alpha = 0.3)+
  geom_vline(xintercept = as.Date(c("2008-12-01","2009-12-01","2010-12-01","2011-12-01","2012-12-01","2013-12-01","2014-12-01","2015-12-01",
                          "2016-12-01","2017-12-01","2018-12-01","2019-12-01","2020-12-01","2021-12-01","2022-12-01")), alpha = .5,
             linetype = "dotted")+
  scale_fill_manual(breaks = c("Lagoon", "Tributary"), 
                     values = c("#7570B3","#66A61E"), 
                     labels = c("Lagoon prediction", "Tributary prediction"))+
  scale_color_manual(breaks = c("d18O"),
                     values = c("black"),
                     labels=(""))+
  scale_x_date(breaks = as.Date(c("2008-01-01","2009-01-01","2010-01-01","2011-01-01","2012-01-01","2013-01-01","2014-01-01","2015-01-01",
                          "2016-01-01","2017-01-01","2018-01-01","2019-01-01","2020-01-01","2021-01-01","2022-01-01")),
               labels = c(as.character(c(2008:2022))),
               limits = c(min(Pikeyears2$date), max(Pikeyears2$date)))+
  scale_y_continuous(limits = c(-8, -1),
                     breaks = c(-8,-7,-6,-5,-4,-3,-2,-1))+
  labs(y = expression(delta^18*"O"["Water/Otolith"]~("VPDB \u2030")),
       fill = expression("predicted"~delta^18*"O"["otolith"]~("VPDB \u2030")~":"),
       color=expression("interpolated"~delta^18*"O"["Water"]~("VPDB \u2030")~":"))+
  theme_classic()+theme(panel.grid.major.y = element_line(size = .3),
        panel.border = element_rect(fill = NA, size = .3),
        plot.margin = margin(c(20,10,1,1)),
        axis.text.x = element_text(color = "transparent", size = 15, angle = 90),
        axis.text.y = element_text(color = "black", size = 15),
        axis.ticks.x = element_line(colour = "transparent"),
        axis.ticks.y = element_line(size = 0.3),
        axis.ticks.length.y = unit(0.05, "cm"),
        axis.title.x = element_text(size = 15, color = "transparent"),
        axis.title.y = element_text(size = 15, color = "black"),
        axis.line = element_line(size = 0.3),
        legend.text = element_text(size = 15, color = "black"),
        legend.title = element_text(size = 15, color = "black"),
        legend.position = "bottom")+
  guides(color=guide_legend(nrow = 2, keyheight = unit(.01, "cm"), keywidth = unit(1, "cm")),
         fill=guide_legend(nrow = 2))

#Plot otolith values
Observed <- ggplot()+
  geom_line(data=Pikeyears3, aes(date, d18O+1, color=area), size = 2)+
  geom_vline(xintercept = as.Date(c("2008-12-01","2009-12-01","2010-12-01","2011-12-01","2012-12-01","2013-12-01","2014-12-01","2015-12-01",
                          "2016-12-01","2017-12-01","2018-12-01","2019-12-01","2020-12-01","2021-12-01","2022-12-01")), alpha = .5,
             linetype = "dotted")+
  scale_fill_manual(breaks = c("Lagoon", "Tributary"), 
                     values = c("#7570B3","#66A61E"), 
                     labels = c("Lagoon prediction", "Tributary prediction"))+
  scale_color_manual(breaks = c("GB", "NRB", "Tributary", "WRB"),
                     values = c("#C5D86D","#AF3800","#00BFB2","#004643"))+
  scale_x_date(breaks = as.Date(c("2008-06-01", "2008-12-01","2009-12-01", "2009-06-01","2010-12-01", "2010-06-01","2011-12-01", "2011-06-01","2012-12-01",
                                  "2012-06-01","2013-12-01", "2013-06-01","2014-12-01", "2014-06-01","2015-12-01", "2015-06-01", "2016-12-01", "2016-06-01",
                                  "2017-12-01", "2017-06-01","2018-12-01", "2018-06-01","2019-12-01", "2019-06-01","2020-12-01", "2020-06-01","2021-12-01",
                                  "2021-06-01","2022-12-01", "2022-06-01")),
               labels = c("Summer 08", "Winter 08","Winter 09", "Summer 09","Winter 10", "Summer 10","Winter 11", "Summer 11","Winter 12", "Summer 12",
                          "Winter 13", "Summer 13","Winter 14", "Summer 14","Winter 15", "Summer 15", "Winter 16", "Summer 16","Winter 17", "Summer 17",
                          "Winter 18", "Summer 18","Winter 19", "Summer 19","Winter 20", "Summer 20","Winter 21", "Summer 21","Winter 22", "Summer 22"),
               limits = c(min(Pikeyears2$date), max(Pikeyears2$date)))+
  scale_y_continuous(limits = c(-8, -1),
                     breaks = c(-8,-7,-6,-5,-4,-3,-2,-1))+
  labs(x = "", y = expression(delta^18*"O"["otolith"]~("VPDB \u2030")), 
       fill = expression("predicted"~delta^18*"O"["otolith"]~("VPDB \u2030")~":"),
       color="area: ")+
  theme_classic()+
  theme(panel.grid.major.y = element_line(size = .3),
        panel.border = element_rect(fill = NA, size = .3),
        plot.margin = margin(c(20,10,1,1)),
        axis.text.x = element_text(color = "black", size = 15, angle = 90),
        axis.text.y = element_text(color = "black", size = 15),
        axis.ticks.x = element_line(colour = "black"),
        axis.ticks.y = element_line(size = 0.3),
        axis.ticks.length.y = unit(0.05, "cm"),
        axis.title = element_text(size = 15, color = "black"),
        axis.line = element_line(size = 0.3),
        legend.text = element_text(size = 15, color = "black"),
        legend.title = element_text(size = 15, color = "black"),
        legend.position = "bottom")

png(filename = "Figures/Yearly-signal-d18O_adapted.png", width = 7000, height = 9000, res = 600)
ggarrange(Temperature, Isotopes, Observed, nrow = 3, ncol = 1, labels = c("A)", "B)", "C)"))
dev.off()
```

```{r d18O observed vs predicted correlation, include=FALSE, eval=FALSE}
rm(list = ls())

#Read in data
Pikeyears2 <- fread("Data/Pike_d18O_indiv_years_interpolated.csv")
Pikeyears3 <- fread("Data/Pike_d18O_mean-area_years_interpolated.csv")
Bodden_iso_oto <- fread("Data/Bodden_iso_prediction.csv")
Fresh_iso_oto <- fread("Data/Tributary_iso_prediction.csv")

#Correlation
Isoto.total <- rbind(Fresh_iso_oto[,c(1, 4:10)], Bodden_iso_oto[,c(1, 4:10)])

Pikeiso <- Pikeyears2%>%
  left_join(Isoto.total, by = c("area", "date"))%>%
  drop_na()

ggplot()+geom_point(aes(x=d18O.x, y=d18O.oto.Patterson, data = Pikeiso))+theme_classic()

#Test prediction against Null model
lm1 <- lm(d18O~d18O.oto.Patterson, data = Pikeiso)
summary(lm1)
lm0 <- lm(d18O~1, data = Pikeiso)
anova(lm1, lm0)

cor(Pikeiso$d18O.x, Pikeiso$d18O.oto.Geffen, method = "spearman")
```

## 3.2. Obtaining a corroborated age estimation
```{r establish reference, include=FALSE, eval=FALSE}
#Script for precision, accuracy metrics and bias plots of corroborated ages

rm(list = ls())

#Read data
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

#join
pikedata <- pikedata%>%
  transmute(id = id,
            Age_refAuto = age_ref,
            Age_refT = age_comb,
            Age_refC = age_combC)%>%
  distinct()

#Precision for combined images
AP_ref_compare <- agePrecision(~Age_refT + Age_refC, data = pikedata)
summary(AP_ref_compare, what = "precision")

#Bias for combined images, second argument is reference age
AB_ref_compare <- ageBias(Age_refT~Age_refC, data = pikedata, ref.lab = "comboT",
                            nref.lab = "comboC")
summary(AB_ref_compare)

#Precision for automated age
AP_auto_combo <- agePrecision(~Age_refAuto + Age_refT, data = pikedata)
AP_auto_comboC <- agePrecision(~Age_refAuto + Age_refC, data = pikedata)
summary(AP_auto_combo, what = "precision")
summary(AP_auto_comboC, what = "precision")

#Bias for automated age
ab_auto_combo <- ageBias(Age_refT ~ Age_refAuto, data = pikedata, ref.lab = "Auto", 
                         nref.lab = "comboT")

ab_auto_comboC <- ageBias(Age_refC ~ Age_refAuto, data = pikedata, ref.lab = "Auto", 
                    nref.lab = "comboC")

summary(ab_auto_combo)
summary(ab_auto_comboC)

save(AP_ref_compare, AB_ref_compare, AP_auto_comboC, AP_auto_combo, ab_auto_comboC, ab_auto_combo, file="Data/Refcompare.RData")

```

```{r Figure 4 Reference age comparison, include=FALSE, eval=FALSE}

rm(list = ls())

load("Data/Refcompare.RData")

Refcompare <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 2) +
  geom_errorbar(data = ab_auto_combo$bias.diff, 
                aes(x=Age_refAuto,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_errorbar(data = ab_auto_comboC$bias.diff, 
                aes(x=Age_refAuto,ymin=LCI,ymax=UCI,color=sig), width = 0, color = "blue")+
  geom_point(data = ab_auto_combo$bias.diff, 
             aes(x=Age_refAuto, y=mean, color=sig, fill=sig),shape=21, size = 2)+
  geom_point(data = ab_auto_comboC$bias.diff, 
             aes(x=Age_refAuto, y=mean, color=sig, fill=sig),shape=18, size = 3, color = "blue")+
  geom_smooth(data=ab_auto_combo$data,aes(x=Age_refAuto,y=diff),size=.65, color = "blue")+
  geom_smooth(data=ab_auto_comboC$data,aes(x=Age_refAuto,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("reader age - automated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(), panel.grid.major = element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 15), 
        axis.text = element_text(colour = "black", size = 15))

Refcompare

```


## 3.3. Aging accuracy and bias of otoliths and scales
```{r agebias, include=FALSE, eval=FALSE}
# Script for age precision, accuracy and bias metrics & plots

rm(list = ls())

# load data
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

#Explanation of columns:
# age_ref: Reference age (automated age counter)
# age_comb: Reader 1 corroboration age (otoliths + overplotted d18O)
# age_combC: Reader 3 corroboration age (otoliths + overplotted d18O)
# age_otoT: Reader 1 visual otolith age estimation
# age_otoK: Reader 2 visual otolith age estimation
# age_scaleT: Reader 1 visual scale age estimation
# age_scaleK: Reader 2 visual scale age estimation
# mrad.comb: otolith radius at last increment
# trad.comb: otolith total radius
# Length_LI: Length at last increment (backcalculation routine below)

pikedata <- pikedata%>%
  transmute(id = id,
            TL = TL,
            Age = age_ref,
            date = date)
# Age precision metrics
AP_scale1_ref <- agePrecision(~age_scaleT + age_ref, data = pikedata)
AP_scaleK_ref <- agePrecision(~age_scaleK + age_ref, data = pikedata)
AP_oto1_ref <- agePrecision(~age_otoT + age_ref, data = pikedata)
AP_otoK_ref <- agePrecision(~age_otoK + age_ref, data = pikedata)

summary(AP_scale1_ref, what = "precision")
summary(AP_scaleK_ref, what = "precision")
summary(AP_oto1_ref, what = "precision")
summary(AP_otoK_ref, what = "precision")

# Signed rank test for CVs
# Reader 1
Structure_vs_ref1 <- data.frame("ID" = pikedata$id, "CVOto" = AP_oto1_ref$detail$CV,
                    "CVScales1" = AP_scale1_ref$detail$CV)
Structure_vs_ref1 <- Structure_vs_ref1 %>% pivot_longer(!ID, names_to = "structure", values_to = "CV")
Structure_vs_ref1$structure <- sub("CVOto", "Oto", Structure_vs_ref1$structure)
Structure_vs_ref1$structure <- sub("CVScales1", "Scales", Structure_vs_ref1$structure)

CVTest1 <- wilcox.test(CV~structure, Structure_vs_ref1)

Structure_vs_refK <- data.frame("ID" = pikedata$id, "CVOto" = AP_otoK_ref$detail$CV,
                    "CVScales1" = AP_scaleK_ref$detail$CV)
Structure_vs_refK <- Structure_vs_refK %>% pivot_longer(!ID, names_to = "structure", values_to = "CV")
Structure_vs_refK$structure <- sub("CVOto", "Oto", Structure_vs_refK$structure)
Structure_vs_refK$structure <- sub("CVScales1", "Scales", Structure_vs_refK$structure)

CVTestK <- wilcox.test(CV~structure, Structure_vs_refK)

CVTest1
CVTestK

#Agebias
ab_scale1_ref <- ageBias(age_scaleT ~ age_ref, data = pikedata, 
                        ref.lab = "ref", nref.lab = "scales2")
ab_scaleK_ref <- ageBias(age_scaleK ~ age_ref, data = pikedata, 
                        ref.lab = "ref", nref.lab = "scalesK")
ab_oto1_ref <- ageBias(age_otoT ~ age_ref, data = pikedata, 
                        ref.lab = "ref", nref.lab = "otoT")
ab_otoK_ref <- ageBias(age_otoK ~ age_ref, data = pikedata, 
                        ref.lab = "ref", nref.lab = "otoK")

summary(ab_scale1_ref, flip.table = T)
summary(ab_scale1_ref, what = "symmetry")
summary(ab_scale1_ref, what = "bias")

summary(ab_scaleK_ref, flip.table = T)
summary(ab_scaleK_ref, what = "symmetry")
summary(ab_scaleK_ref, what = "bias")

summary(ab_oto1_ref, flip.table = T)
summary(ab_oto1_ref, what = "symmetry")
summary(ab_oto1_ref, what = "bias")

summary(ab_otoK_ref, flip.table = T)
summary(ab_otoK_ref, what = "symmetry")
summary(ab_otoK_ref, what = "bias")

# Save data
save(AP_oto1_ref, AP_otoK_ref, AP_scale1_ref, AP_scaleK_ref, ab_oto1_ref, ab_otoK_ref, ab_scale1_ref, ab_scaleK_ref, file="Data/AgeBias.RData")
```

```{r agebiastests, include=FALSE, eval=FALSE}
rm(list = ls())

# load data
load("Data/AgeBias.RData")
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

# Age precision metrics

summary(ab_scale1_ref, flip.table = T)
summary(ab_scale1_ref, what = "symmetry")
summary(ab_scale1_ref, what = "bias")

summary(ab_scaleK_ref, flip.table = T)
summary(ab_scaleK_ref, what = "symmetry")
summary(ab_scaleK_ref, what = "bias")

summary(ab_oto1_ref, flip.table = T)
summary(ab_oto1_ref, what = "symmetry")
summary(ab_oto1_ref, what = "bias")

summary(ab_otoK_ref, flip.table = T)
summary(ab_otoK_ref, what = "symmetry")
summary(ab_otoK_ref, what = "bias")


summary(AP_scale1_ref, what = "precision")
summary(AP_scaleK_ref, what = "precision")
summary(AP_oto1_ref, what = "precision")
summary(AP_otoK_ref, what = "precision")

# Signed rank test for CVs
# Reader 1
Structure_vs_ref1 <- data.frame("ID" = pikedata$id, "CVOto" = AP_oto1_ref$detail$CV,
                    "CVScales1" = AP_scale1_ref$detail$CV)
Structure_vs_ref1 <- Structure_vs_ref1 %>% pivot_longer(!ID, names_to = "structure", values_to = "CV")
Structure_vs_ref1$structure <- sub("CVOto", "Oto", Structure_vs_ref1$structure)
Structure_vs_ref1$structure <- sub("CVScales1", "Scales", Structure_vs_ref1$structure)

CVTest1 <- wilcox.test(CV~structure, Structure_vs_ref1)

# Reader 2
Structure_vs_refK <- data.frame("ID" = pikedata$id, "CVOto" = AP_otoK_ref$detail$CV,
                    "CVScales1" = AP_scaleK_ref$detail$CV)
Structure_vs_refK <- Structure_vs_refK %>% pivot_longer(!ID, names_to = "structure", values_to = "CV")
Structure_vs_refK$structure <- sub("CVOto", "Oto", Structure_vs_refK$structure)
Structure_vs_refK$structure <- sub("CVScales1", "Scales", Structure_vs_refK$structure)

CVTestK <- wilcox.test(CV~structure, Structure_vs_refK)
```

```{r Table 1 age bias, include=FALSE, eval=FALSE}

rm(list = ls())

load("Data/AgeBias.RData")

Overview_agebias <- cbind(rbind(summary(AP_scale1_ref, what = "precision"),
                                summary(AP_scaleK_ref, what = "precision"),
                                summary(AP_oto1_ref, what = "precision"),
                                summary(AP_otoK_ref, what = "precision")),
                          rbind(summary(AP_scale1_ref, what = "absolute",,3),
                                summary(AP_scaleK_ref, what = "absolute",,3), 
                                summary(AP_oto1_ref, what = "absolute",,3),
                                summary(AP_otoK_ref, what = "absolute",,3)))

Overview_agebias$sample <- c("Reader 1 scale age",  "Reader 2 scale age", 
                             "Reader1 otolith age", "Reader 2 otolith age")

Overview_agebias <- data.frame(Overview_agebias)
Overview_agebias$X1 <- Overview_agebias$X1 + Overview_agebias$X0
Overview_agebias$X2 <- Overview_agebias$X1 + Overview_agebias$X2

Overview_agebias[,c(3:11)] <- round(Overview_agebias[,c(3:11)], 1)
Overview_agebias$PercAgree <- paste(Overview_agebias$PercAgree, "%")
Overview_agebias$X1 <- paste(Overview_agebias$X1, "%")
Overview_agebias$X2 <- paste(Overview_agebias$X2, "%")

Overview <- flextable(Overview_agebias, col_keys = c("sample", "validn", "PercAgree","X1",
                                                     "X2", "ACV", "AAD", "APE"))%>%
  fontsize(part = "all", size = 10)%>%
  bold(part = "header")%>%
  set_header_labels(sample = "Structure", 
                    validn = "N", 
                    PercAgree = "% agreement",
                    X1 = "\u00B1 1 year", 
                    X2 = "\u00B1 2 years", 
                    ASD = "Average standard deviation",
                    ACV = "Average coefficient of variation [%]", 
                    AAD = "Average absolute deviation", 
                    APE = "Average percent error [%]")%>%
  set_caption("Summary of aging precision and accuracy metrics")%>%
  colformat_double(j = "ACV", suffix = "%")%>%
  colformat_double(j = "APE", suffix = "%")%>%
  colformat_double(j = "PercAgree", suffix = "%")%>%
  colformat_double(j = "X1", suffix = "%")%>%
  colformat_double(j = "X2", suffix = "%")%>%
  set_table_properties(layout = "autofit")

Overview
```

```{r Figure 5 agebiasplots, include=FALSE, eval=FALSE}

rm(list = ls())

load("Data/AgeBias.RData")

#Otoliths Timo
a <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 1) +
  geom_errorbar(data = ab_oto1_ref$bias.diff, 
                aes(x=age_ref,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_point(data = ab_oto1_ref$bias.diff, 
             aes(x=age_ref, y=mean, color=sig, fill=sig),shape=21, size = 2) +
  geom_smooth(data=ab_oto1_ref$data,aes(x=age_ref,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("otolith age - corroborated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(), 
        panel.grid.major = element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 10), 
        axis.text = element_text(colour = "black", size = 10))

#Otoliths Korbi
b <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 1) +
  geom_errorbar(data = ab_otoK_ref$bias.diff, 
                aes(x=age_ref,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_point(data = ab_otoK_ref$bias.diff, 
             aes(x=age_ref, y=mean, color=sig, fill=sig),shape=21, size = 2) +
  geom_smooth(data=ab_otoK_ref$data,aes(x=age_ref,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("otolith age - corroborated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(), 
        panel.grid.major = element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 10), 
        axis.text = element_text(colour = "black", size = 10))

#Scales Timo
c <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 1) +
  geom_errorbar(data = ab_scale1_ref$bias.diff, 
                aes(x=age_ref,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_point(data = ab_scale1_ref$bias.diff, 
             aes(x=age_ref, y=mean, color=sig, fill=sig),shape=21, size = 2) +
  geom_smooth(data=ab_scale1_ref$data,aes(x=age_ref,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("scale age - corroborated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(),
        panel.grid.major = element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 10), 
        axis.text = element_text(colour = "black", size = 10))

#Scales Korbi
d <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 1) +
  geom_errorbar(data = ab_scaleK_ref$bias.diff, 
                aes(x=age_ref,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_point(data = ab_scaleK_ref$bias.diff, 
             aes(x=age_ref, y=mean, color=sig, fill=sig),shape=21, size = 2) +
  geom_smooth(data=ab_scaleK_ref$data,aes(x=age_ref,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("scale age - corroborated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(), 
        panel.grid.major =  element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 10), 
        axis.text = element_text(colour = "black", size = 10))

plots <- ggarrange(a, b, c, d, ncol = 2, nrow = 2, 
                    labels = c("A", "B", "C", "D"), label.x = 0.9, font.label = list(size = 15))

plots
```

## 3.4. Population-level growth of pike using age data from different aging structures
```{r Fraser Lee Backcalculation, include=FALSE, eval=FALSE}

# Script to convert length at capture to length at last increment using Fraser Lee equation

rm(list = ls())

# Read age data with radii
pikedata <- read.delim("Data/Pike_ages_all_with_TL.txt", header = T, 
                       stringsAsFactors = F)

# Visual examination
ggplot(pikedata, aes(log(trad_comb), log(TL))) + geom_point() + theme_minimal()
ggplot(pikedata, aes(trad_comb, TL)) + geom_point() + theme_minimal()

# Linear model of length at capture vs otolith radius at last increment
lmOto <- lm(TL~trad_comb, data = pikedata)
loglmOto <- lm(log(TL)~log(trad_comb), data = pikedata)
summary(lmOto)
summary(loglmOto)

# Extract coefficients for Backcalculation
a <- coefficients(loglmOto)[[1]]
b <- coefficients(loglmOto)[[2]]

# Add column with backcalculated lengths
pikedata <- pikedata %>%
  mutate(Length_LI = exp(log(TL)+b*(log(mrad_comb)-log(trad_comb))))
pikedata$Length_LI <- ifelse(pikedata$month <= 4, pikedata$TL, pikedata$Length_LI)

# Save table in data
write.table(pikedata, "Data/Pike_ages_all_with_TL_backcalulated.txt", sep = "\t", 
            dec = ".", row.names = F)
```

```{r growth model multimodel comparison, include=FALSE, eval=FALSE}
# Script to compare prior constellations for growth models

rm(list = ls())

# Load pike data
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

# Load list of priors (fishbase credible estimates, as of database version December 2021)
priors <- read.delim("Data/Priors_pike.csv", sep = ";", header = T, stringsAsFactors = F)

# Transform mm to cm
pikedata$age_oto <- round(rowMeans(pikedata[,c("age_otoT", "age_otoK")]),0)
pikedata$age_scale <- round(rowMeans(pikedata[,c("age_scaleT", "age_scaleK")]),0)
pikedata <- pikedata %>% filter(area != "KD")

# Cleanup
growthdata <- pikedata %>%
  transmute(id = id,
            sex = sex,
            weight = weight,
            TL = TL/10,
            L = Length_LI/10,
            date = date,
            area = area,
            age_ref = age_ref,
            age_oto = age_oto,
            age_scale = age_scale)

# Write data lists for stan
#Variance at 10% mean
standata_ref_1 = list(
  Length = growthdata$L,
  Age = growthdata$age_ref,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/10,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

#Variance at 5% mean
standata_ref_2 = list(
  Length = growthdata$L,
  Age = growthdata$age_ref,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/20,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

#Only error structure
standata_ref_3 = list(
  Length = growthdata$L,
  Age = growthdata$age_ref,
  N = nrow(growthdata),
  linf_mean = 0, #alt: mean^2/variance & variance/mean
  linf_var = 150,
  t0_mean = 0,
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

# Stan Code path
stancode1 <- "Stan/Simple_VBGF_TZero.stan"

# Fit models
fit_ref_1 = stan(stancode1, iter = 10000, data = standata_ref_1)
fit_ref_2 = stan(stancode1, iter = 10000, data = standata_ref_2)
fit_ref_3 = stan(stancode1, iter = 10000, data = standata_ref_3)

# Check
print(fit_ref_1, pars = c("LInf", "tZero", "k", "sigma" ))
print(fit_ref_2, pars = c("LInf", "tZero", "k", "sigma" ))
print(fit_ref_3, pars = c("LInf", "tZero", "k", "sigma" ))

#LOO
#All model into list for convenience when doing repeated operations
fits <- list(mod1=fit_ref_1, mod2 = fit_ref_2, mod3 = fit_ref_3)

#Loo object for each model
loos <- lapply(fits, loo, pars = "log_lik")
loos$mod1
print(loo_compare(loos), simplify = F)

looics = sapply(loos, function(x) x$estimates['looic', 'Estimate'])
delta_looic = looics - min(looics)
wi = exp(-0.5*delta_looic) / sum(exp(-0.5*delta_looic))
round(rbind(looic = looics, dlooic = delta_looic, weight = wi), 2)

# Save data
save(fit_ref_1, fit_ref_2, fit_ref_3, loos, file="Data/LOO_compare.RData")
```

```{r multimodel eval, include=FALSE, eval=FALSE}
load("Data/LOO_compare.RData")

#eval
pairs(fit_ref_1, pars = c("LInf", "k", "tZero", "sigma"))
pairs(fit_ref_2, pars = c("LInf", "k", "tZero", "sigma"))
pairs(fit_ref_3, pars = c("LInf", "k", "tZero", "sigma"))

samples_ref1 <- as.matrix(fit_ref_1, pars=c("LInf", "k", "tZero", "sigma"))
samples_ref2 <- as.matrix(fit_ref_2, pars=c("LInf", "k", "tZero", "sigma"))
samples_ref3 <- as.matrix(fit_ref_3, pars=c("LInf", "k", "tZero", "sigma"))

mcmc_combo(samples_ref1, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))
mcmc_combo(samples_ref2, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))
mcmc_combo(samples_ref3, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))

```

```{r Compare LOO scores table, include=FALSE, eval=FALSE}
rm(list = ls())

load("Data/LOO_compare.RData")

loos$mod1
print(loo_compare(loos), simplify = F)

looics = sapply(loos, function(x) x$estimates['looic', 'Estimate'])
delta_looic = looics - min(looics)
wi = exp(-0.5*delta_looic) / sum(exp(-0.5*delta_looic))
Loo <- as.data.frame(round(rbind(looic = looics, dlooic = delta_looic, weight = wi), 2))

Loo <- Loo%>%add_rownames()

Table <- Loo %>% flextable()%>%set_header_labels(rowname="", 
                                                 mod1="Model 1", 
                                                 mod2="Model 2",
                                                 mod3="Model 3")
save_as_docx(Table, path = "Tables/Loocompare.docx")
```

```{r growth models, include=FALSE, eval=FALSE}
# Script to fit VB growth curve with chosen prior structure to age data sets

rm(list = ls())

# load data
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

priors <- read.delim("Data/Priors_pike.csv", sep = ";", header = T, stringsAsFactors = F)

# Transform TL mm to TL cm
pikedata$age_oto <- round(rowMeans(pikedata[,c("age_otoT", "age_otoK")]),0)
pikedata$age_scale <- round(rowMeans(pikedata[,c("age_scaleT", "age_scaleK")]),0)
pikedata <- pikedata %>% filter(area != "KD")

# Remove 0

pikedata[pikedata$age_scale == 0,]$age_scale <- 1

# Cleanup
growthdata <- pikedata %>%
  transmute(id = id,
            sex = sex,
            weight = weight,
            TL = TL/10,
            L = Length_LI/10,
            date = date,
            area = area,
            age_ref = age_ref,
            age_oto = age_oto,
            age_scale = age_scale)

# Write data lists for stan
# Reference age
standata_ref = list(
  Length = growthdata$L,
  Age = growthdata$age_ref,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/10,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

# Otolith age
standata_oto = list(
  Length = growthdata$L,
  Age = growthdata$age_oto,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/10,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

# Scale age
standata_scale = list(
  Length = growthdata$L,
  Age = growthdata$age_scale,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/10,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

# Modeling
stancode1 <- "Stan/Simple_VBGF_TZero.stan"

fit_ref = stan(stancode1, iter = 10000, data = standata_ref)
fit_oto = stan(stancode1, iter = 10000, data = standata_oto)
fit_scale = stan(stancode1, iter = 10000, data = standata_scale)

# check
print(fit_ref, pars = c("LInf", "tZero", "k", "sigma" ))
print(fit_oto, pars = c("LInf", "tZero", "k", "sigma" ))
print(fit_scale, pars = c("LInf", "tZero", "k", "sigma" ))

#Evaluation
pairs(fit_ref, pars = c("LInf", "k", "tZero", "sigma"))
pairs(fit_oto, pars = c("LInf", "k", "tZero", "sigma"))
pairs(fit_scale, pars = c("LInf", "k", "tZero", "sigma"))

samples_ref <- as.matrix(fit_ref, pars=c("LInf", "k", "tZero", "sigma"))
samples_oto <- as.matrix(fit_oto, pars=c("LInf", "k", "tZero", "sigma"))
samples_scale <- as.matrix(fit_scale, pars=c("LInf", "k", "tZero", "sigma"))

mcmc_combo(samples_ref, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))
mcmc_combo(samples_oto, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))
mcmc_combo(samples_scale, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))

save(growthdata, fit_ref, fit_oto, fit_scale, samples_ref, samples_oto, samples_scale, file="Data/fit.RData")
```

```{r Inference, include=FALSE, eval=FALSE}
# Code to compare parameter estimates between aging structures

rm(list = ls())

load("Data/fit.RData")

#Transform LINf to array
sample_LInf1 <- as.array(fit_ref, pars = c("LInf"))
sample_LInf2 <- as.array(fit_oto, pars = c("LInf"))
sample_LInf3 <- as.array(fit_scale, pars = c("LInf"))

#Transform k to array
sample_k1 <- as.array(fit_ref, pars = c("k"))
sample_k2 <- as.array(fit_oto, pars = c("k"))
sample_k3 <- as.array(fit_scale, pars = c("k"))

# Transform t0 to array
sample_tzero1 <- as.array(fit_ref, pars = c("tZero"))
sample_tzero2 <- as.array(fit_oto, pars = c("tZero"))
sample_tzero3 <- as.array(fit_scale, pars = c("tZero"))

#Transform sigma (error term) to array
sample_sigma1 <- as.array(fit_ref, pars = c("sigma"))
sample_sigma2 <- as.array(fit_oto, pars = c("sigma"))
sample_sigma3 <- as.array(fit_scale, pars = c("sigma"))

# Compare estimates
#LInf
bayesplot_grid((mcmc_intervals(sample_LInf1)), (mcmc_intervals(sample_LInf2)),(mcmc_intervals(sample_LInf3)), xlim = c(80, 150), 
               titles = c("Reference", "Otoliths", "Scales"))

#k
bayesplot_grid((mcmc_intervals(sample_k1)), (mcmc_intervals(sample_k2)),(mcmc_intervals(sample_k3)), xlim = c(.1,.6), 
               titles = c("Reference", "Otoliths", "Scales"))

#t0
bayesplot_grid((mcmc_intervals(sample_tzero1)), (mcmc_intervals(sample_tzero2)),(mcmc_intervals(sample_tzero3)), xlim = c(0,-1), 
               titles = c("Reference", "Otoliths", "Scales"))

#sigma
bayesplot_grid((mcmc_intervals(sample_sigma1)), (mcmc_intervals(sample_sigma2)),(mcmc_intervals(sample_sigma3)), xlim = c(10,20), 
               titles = c("Reference", "Otoliths", "Scales"))

#area plots are a bit more informative
#LInf
bayesplot_grid(mcmc_areas(sample_LInf1, prob = 0.8, prob_outer = 0.90, point_est = "median"),
               mcmc_areas(sample_LInf2, prob = 0.8, prob_outer = 0.90, point_est = "median"),
               mcmc_areas(sample_LInf3, prob = 0.8, prob_outer = 0.90, point_est = "median"),
               xlim = c(80, 150))

#k
bayesplot_grid(mcmc_areas(sample_k1, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_k2, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_k3, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               xlim = c(.1, .6))

#t0
bayesplot_grid(mcmc_areas(sample_tzero1, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_tzero2, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_tzero3, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               xlim = c(-1, 0))

#sigma
bayesplot_grid(mcmc_areas(sample_sigma1, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_sigma2, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_sigma3, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               xlim = c(0, 20))
```

```{r extract prediction, include=FALSE, eval=FALSE}
# Script to extract Length-at-age predictions from growth models for later plotting
rm(list = ls())

#load data
load("Data/fit.RData")

# Prediction function

LTpredict<- function(pars, Age){
  pars[1]*(1-exp(-pars[2]*(Age-pars[3])))
}

Pred_ref <- t(apply(samples_ref[, c(1, 2, 3)], 1, LTpredict, Age = 0:15))
Pred_oto <- t(apply(samples_oto[, c(1, 2, 3)], 1, LTpredict, Age = 0:15))
Pred_scale <- t(apply(samples_scale[, c(1, 2, 3)], 1, LTpredict, Age = 0:15))

Quantile1 <- data.frame(t(apply(Pred_ref, 2, quantile, c(0.5, 0.05, 0.95))))
colnames(Quantile1) <- c("median", "lower", "upper")
Quantile1$age <- c(0:15)


Quantile2 <- data.frame(t(apply(Pred_oto, 2, quantile, c(0.5, 0.05, 0.95))))
colnames(Quantile2) <- c("median", "lower", "upper")
Quantile2$age <- c(0:15)

Quantile3 <- data.frame(t(apply(Pred_scale, 2, quantile, c(0.5, 0.05, 0.95))))
colnames(Quantile3) <- c("median", "lower", "upper")
Quantile3$age <- c(0:15)

# Save data object
save(fit_ref, fit_oto, fit_scale, samples_ref, samples_oto, samples_scale, Quantile1, Quantile2, Quantile3, growthdata, file="Data/Growthmodel.RData")
```

```{r Figure 6 Growthplots, include=FALSE, eval=FALSE}

rm(list = ls())

# Load data
load("Data/Growthmodel.RData")

# Reference curve
Curve_ref <- ggplot() + xlab("Age (years)") + ylab("Total length (cm)") +
  geom_ribbon(data = Quantile1, aes(x = age, ymin = lower, ymax = upper), 
              fill = "#1B9E77", alpha = 0.2)+
  geom_line(data = Quantile1, aes(x = age, y = median), color = "#1B9E77", size = 1.2)+
  geom_point(data = growthdata, aes(x = age_ref, y = L), color = "black")+
  annotate("text", x = 7, y = 50, label = "L[infinity]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 50, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 50, label = paste(round(mean(samples_ref[,1]),2), "cm"), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 30, label = "k", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 30, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 30, label = round(mean(samples_ref[,2]),2), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 10, label = "t[0]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 10, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 10, label = paste(round(mean(samples_ref[,3]),2), "yr"), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  scale_x_continuous(expand = c(0, 0), limits = c(0, 16), breaks = c(1:15), 
                     labels = c("1","","3","","5","","7","","9","","11","","13","","15"))+ 
  scale_y_continuous(expand = c(0, 0), limits = c(0, 140), 
                     breaks = c(0,15,30,45,60,75,90,105,120),
                     labels = c("0","","30","","60","","90","","120"))+
  theme(axis.line = element_line(size = 1, colour = "black", linetype = 1),
        axis.ticks = element_line(size = 1, colour = "black"),
        axis.text = element_text(size = 15, colour = "black"),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        panel.background = element_blank(),
        #panel.grid.major = element_line(color = "grey", linetype = 3, size = .2),
        plot.title = element_text(size = 15, vjust = -5, hjust = 0.1))

# Otolith curve
Curve_oto <- ggplot() + xlab("Age (years)") + ylab("Total length (cm)") +
  geom_ribbon(data = Quantile2, aes(x = age, ymin = lower, ymax = upper), fill = "#D95F02", alpha = 0.2)+
  geom_line(data = Quantile2, aes(x = age, y = median), color = "#D95F02", size = 1.2)+
  geom_point(data = growthdata, aes(x = age_oto, y = L), color = "black")+
  geom_ribbon(data = Quantile1, aes(x = age, ymin = lower, ymax = upper), fill = "#1B9E77", alpha = 0.2)+
  geom_line(data = Quantile1, aes(x = age, y = median), color = "#1B9E77", size = 1.2)+
  #geom_point(data = pikedata, aes(x = age_comb, y = length_comb), color = "#1B9E77")+
  annotate("text", x = 7, y = 50, label = "L[infinity]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 50, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 50, label = paste(round(mean(samples_oto[,1]),2), "cm"), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 30, label = "k", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 30, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 30, label = round(mean(samples_oto[,2]),2), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 10, label = "t[0]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 10, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 10, label = paste(round(mean(samples_oto[,3]),2), "yr"), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  scale_x_continuous(expand = c(0, 0), limits = c(0, 16), breaks = c(1:15), 
                     labels = c("1","","3","","5","","7","","9","","11","","13","","15"))+ 
  scale_y_continuous(expand = c(0, 0), limits = c(0, 140), breaks = c(0,15,30,45,60,75,90,105,120),
                     labels = c("0","","30","","60","","90","","120"))+
  theme(axis.line = element_line(size = 1, colour = "black", linetype = 1),
        axis.ticks = element_line(size = 1, colour = "black"),
        axis.text = element_text(size = 15, colour = "black"),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        panel.background = element_blank(),
        #panel.grid.major = element_line(color = "grey", linetype = 3, size = .2),
        plot.title = element_text(size = 15, vjust = -5, hjust = 0.1))

# Scale curve-------------------------------------------------------------------------------
Curve_scale <- ggplot() + xlab("Age (years)") + ylab("Total length (cm)") +
  geom_ribbon(data = Quantile3, aes(x = age, ymin = lower, ymax = upper), fill = "#D95F02", alpha = 0.2)+
  geom_line(data = Quantile3, aes(x = age, y = median), color = "#D95F02", size = 1.2)+
  geom_point(data = growthdata, aes(x = age_scale, y = L), color = "black")+
  geom_ribbon(data = Quantile1, aes(x = age, ymin = lower, ymax = upper), fill = "#1B9E77", alpha = 0.2)+
  geom_line(data = Quantile1, aes(x = age, y = median), color = "#1B9E77", size = 1.2)+
  #geom_point(data = pikedata, aes(x = age_comb, y = length_comb), color = "#1B9E77")+
  annotate("text", x = 7, y = 50, label = "L[infinity]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 50, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 50, label = paste(round(mean(samples_scale[,1]),2), "cm"), parse = F, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 30, label = "k", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 30, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 30, label = round(mean(samples_scale[,2]),2), parse = F, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 10, label = "t[0]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 10, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 10, label = paste(round(mean(samples_scale[,3]),2), "yr"), parse = F, hjust = 0, color = "black", size = 4.5)+
  scale_x_continuous(expand = c(0, 0), limits = c(0, 16), breaks = c(1:15), 
                     labels = c("1","","3","","5","","7","","9","","11","","13","","15"))+ 
  scale_y_continuous(expand = c(0, 0), limits = c(0, 140), breaks = c(0,15,30,45,60,75,90,105,120),
                     labels = c("0","","30","","60","","90","","120"))+
  theme(axis.line = element_line(size = 1, colour = "black", linetype = 1),
        axis.ticks = element_line(size = 1, colour = "black"),
        axis.text = element_text(size = 15, colour = "black"),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        panel.background = element_blank(),
        #panel.grid.major = element_line(color = "grey", linetype = 3, size = .2),
        plot.title = element_text(size = 15, vjust = -5, hjust = 0.1))

Curves <- ggarrange(Curve_ref, Curve_oto, Curve_scale, ncol = 3, nrow = 1, 
                    labels = c("A)", "B)", "C)"), label.x = 0, font.label = list(size = 15))
Curves
```

```{r Table 2 growthtable, include=FALSE, eval=FALSE}
# Script to concatenate growth data into table

rm(list = ls())

#load data
load("Data/Growthmodel.RData")

CI1LInf <- quantile(extract(fit_ref, pars = "LInf")[[1]], probs = c(0.05, 0.95))
CI2LInf <- quantile(extract(fit_oto, pars = "LInf")[[1]], probs = c(0.05, 0.95))
CI3LInf <- quantile(extract(fit_scale, pars = "LInf")[[1]], probs = c(0.05, 0.95))

CIsLInf <- rbind(CI1LInf, CI2LInf, CI3LInf)

SDsLInf <- CIsLInf[,2]-CIsLInf[,1]

CI1k <- quantile(extract(fit_ref, pars = "k")[[1]], probs = c(0.05, 0.95))
CI2k <- quantile(extract(fit_oto, pars = "k")[[1]], probs = c(0.05, 0.95))
CI3k <- quantile(extract(fit_scale, pars = "k")[[1]], probs = c(0.05, 0.95))

CIsk <- rbind(CI1k, CI2k, CI3k)

SDsk <- CIsk[,2]-CIsk[,1]

CI1tZero <- quantile(extract(fit_ref, pars = "tZero")[[1]], probs = c(0.05, 0.95))
CI2tZero <- quantile(extract(fit_oto, pars = "tZero")[[1]], probs = c(0.05, 0.95))
CI3tZero <- quantile(extract(fit_scale, pars = "tZero")[[1]], probs = c(0.05, 0.95))

CIstZero <- rbind(CI1tZero, CI2tZero, CI3tZero)

SDstZero <- CIstZero[,2]-CIstZero[,1]

Overview <- rbind(c(mean(samples_ref[,c(1)]), mean(samples_ref[,c(2)]), mean(samples_ref[,c(3)])),
                  c(mean(samples_oto[,c(1)]), mean(samples_oto[,c(2)]), mean(samples_oto[,c(3)])),
                  c(mean(samples_scale[,c(1)]), mean(samples_scale[,c(2)]), mean(samples_scale[,c(3)])))
                  

Overview <- data.frame(Overview)
Overview$sample <- c("Corroborated age", "Otolith age estimate", "Scale age estimate")
Overview$N <- 86

Overview$LInf <- paste(round(Overview$X1,1), "\u00B1", .5*(round(SDsLInf, 1)))
Overview$k <- paste(round(Overview$X2,2), "\u00B1", .5*(round(SDsk, 2)))
Overview$tZero <- paste(round(Overview$X3,1), "\u00B1", .5*(round(SDstZero, 1)))



Overviewtable <- flextable(Overview, col_keys = c("sample", "N", "LInf", "k", "tZero"))%>%
  fontsize(part = "header", size = 10)%>%
  bold(part = "header")%>%
  set_header_labels(sample = "Sample", LInf = "L \u221E [cm]", 
                                   k = "Body growth coefficient k", tZero = "Age at size 0 [yr]", N = "N")%>%
  set_table_properties(width = 0.99, layout = "autofit")%>%
  theme_vanilla()%>%
  set_caption("Summary of VBGF paramteters from different aging methods")

Overviewtable
```

## 3.5. Fisheries management reference points and optimal minimum-length limit
**Credit for the code for this chapter goes to my coauthor, Dr. Elias Ehrlich**
```{r model parameters, include=FALSE, eval=FALSE}
####################################
# Parameters - for Age Pike Model
# Created by: Elias Ehrlich
####################################
############
# Parameters
############
Bodden_area = 125200 #according to Rob van Gemerts' data in handover folder #126560 #170000 # [ha] 

a_max = 15                # Maximum age [years]
#M_min = 0.15              # Minimum adult natural mortality rate [year^-1]
M_min = 0.25              # Minimum adult natural mortality rate [year^-1]
theta = 0.5               # Lorenzen size-dependent mortality power (0-1.2)
#theta = 1.0               # Lorenzen size-dependent mortality power (0-1.2)

alpha_w = 0.0045          # Length-weight scaling constant
beta_w = 3.107            # Allometric parameter

l_mat = 375               # Length-at-maturation [mm]
alpha_f = 9.8             # Fecundity-weight scaling constant
beta_f = 1.12             # Power parameter relating fecundity to weight

R0 = 1.0*10^6             # Average total age-1 recruitment in the unfished stock []
SexRatioRecruits = 0.5    # females/(females+males)
CR = 6.1                  # Compensation ratio (paper: Goodyear 1980) []

#lmin_c = 375              # Minimum length at which vulnverable to capture [mm] 
lmin_c = 400              # Minimum length at which vulnverable to capture [mm] 
lmax_c = 1500             # Maximum length at which vulnerable to capture [mm]
#lmin_r = 375              # Minimum length at which vulnverable to capture [mm] 
lmin_r = 500              # Minimum length vulnerable to harvest [mm]
lmax_r = 1500             # Maximum length vulnerable to harvest [mm]

l_troph = 1000            # Minimum total length of a trophy fish [mm]

#F_mort = 0.1              # Instantaneous fishing mortality on individuals with selectivity of 1 [year^-1] (current situation)
F_mort = 0.2              # Instantaneous fishing mortality on individuals with selectivity of 1 [year^-1] (current situation)
d = 0.078                 # Discard mortality []; e.g. f_h=0.1 --> 10 % of released fish die 

# Growth parameters based on 3 different aging methods using scales, otoliths or the corroborated age, respectively (=3 values for each parameter)
measure_L8 = c(1236, 1010, 986.0)            # Measured mean asymptotic length L_8 (van Bertalanffy growth function VBGF) [mm] 
measure_k = c(0.17, 0.28, 0.28)              # Measured VBGF growth coefficient k [year^-1] for scale, otolith and corroborated age, respectively
measure_t0 = c(-0.4, -0.4, -0.4)             # Measured theoretical age at length of 0 t_0 [years] for scale, otolith and corroborated age, respectively
sd_L8 = c(198, 85.5, 109.5)                  # Standard deviation of L_8 [mm] of measurement for scale, otolith and corroborated age, respectively
sd_k = c(0.05, 0.055, 0.08)                  # Standard deviation of k [year^-1] of measurement for scale, otolith and corroborated age, respectively
sd_t0 = c(0.15, 0.15, 0.15)                  # Standard deviation of t_0 [years] of measurement for scale, otolith and corroborated age, respectively

CI_5_L8 = c(1055.5, 931.7, 889.2)            # 5 % confidence level for L_8 estimates
CI_95_L8 = c(1451.6, 1102.8, 1108.5)         # 95 % confidence level for L_8 estimates
CI_5_k = c(0.13, 0.22, 0.21)                 # 5 % confidence level for k estimates
CI_95_k = c(0.22, 0.34, 0.37)                # 95 % confidence level for k estimates
CI_5_t0 = c(-0.56, -0.55, -0.58)             # 5 % confidence level for t_0 estimatees
CI_95_t0 = c(-0.25, -0.25, -0.28)            # 95 % confidence level for t_0 estimates

cv = 0.13                                   # Coefficient of variation in VBGF among individuals

# Random seed number for reproducibility of results
RandomSeedNr = 126
```

```{r pike age model & figure 7, include=FALSE, eval=FALSE}
#############################################################################################################
# Pike model: Effect of different ageing methods on fishery reference points and optimal minimum length limit  
# Code author: Elias Ehrlch           
#############################################################################################################

setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to source file (for using RStudio)

#############################
# Load Packages and functions
#############################
library(matrixStats)
library(reshape2)
library(ggplot2)
library(patchwork)

#########
# Setting
#########
SAVE = 0                  # Set to 1 to save png plot and to 0 if not

##############
# Loading Data
##############
#source("Data/AgePikeModel_Parameters.R") # Import parameters

path = "Data/SimData/FishRefPoints/"
F_mort_vec = readRDS(file=paste0(path, "F_mort.rds"))               # Scenarios of instantaneous fishing mortalities
N_vec_rep = readRDS(file=paste0(path, "N_F_mort.rds"))              # Temporal average total stock size
HarvN_vec_rep = readRDS(file=paste0(path, "HarvN_F_mort.rds"))      # Temporal average harvestable stock size
VulnN_vec_rep = readRDS(file=paste0(path, "VulnN_F_mort.rds"))      # Temporal average stock size vulnerable to catch
TrophyN_vec_rep = readRDS(file=paste0(path, "TrophyN_F_mort.rds"))  # Temporal average trophy stock size
AmountTrophy_vec_rep = readRDS(file=paste0(path, "AmountTrophy_F_mort.rds"))  # Temporal average amount of trophy fish in population
B_vec_rep = readRDS(file=paste0(path, "B_F_mort.rds"))              # Temporal average total biomass
Y_vec_rep = readRDS(file=paste0(path, "Y_F_mort.rds"))              # Temporal average yield
YN_vec_rep = readRDS(file=paste0(path, "YN_F_mort.rds"))            # Temporal average yield

n_meth = dim(N_vec_rep) [3]                 # Number of different aging methods
n_rep = dim(N_vec_rep) [2]                  # Number of random samples of growth parameters per aging method
n = dim(N_vec_rep) [1]                      # Number of scenarios of F

########################################
# Calculating fisheries reference points
########################################
# Fishery reference points for each random sample of growth parameters for the n_meth=3 aging methods
MSY_rep = matrix(NA, n_rep, n_meth)
F_MSY_rep = matrix(NA, n_rep, n_meth)
B_MSY_rep = matrix(NA, n_rep, n_meth)
N_MSY_rep = matrix(NA, n_rep, n_meth)
HarvN_MSY_rep = matrix(NA, n_rep, n_meth)
VulnN_MSY_rep = matrix(NA, n_rep, n_meth)
TrophyN_MSY_rep = matrix(NA, n_rep, n_meth)

YNmax_rep = matrix(NA, n_rep, n_meth) 

for (h in 1:n_meth){
  MSY_rep[,h] = apply(Y_vec_rep[,,h], 2, max)                 # MSY (=highest temporal mean yield over all scenarios) for each growth parameter sample
  Index_max = apply(Y_vec_rep[,,h], 2, which.max)             # Index of MSY in output metrix Y_vec_rep[,,h] for each growth parameter sample
  F_MSY_rep[,h] = F_mort_vec[Index_max]                       # F_MSY for each growth parameter sample
  for (j in 1:n_rep){
    B_MSY_rep[j,h] = B_vec_rep[Index_max[j],j,h]              # B_MSY for each growth parameter sample
    N_MSY_rep[j,h] = N_vec_rep[Index_max[j],j,h]              # N_MSY for each growth parameter sample
    HarvN_MSY_rep[j,h] = HarvN_vec_rep[Index_max[j],j,h]  
    VulnN_MSY_rep[j,h] = VulnN_vec_rep[Index_max[j],j,h]  
    TrophyN_MSY_rep[j,h] = TrophyN_vec_rep[Index_max[j],j,h]
  }
  YNmax_rep[,h] = apply(YN_vec_rep[,,h], 2, max)              # Maximum number of harvested fish for each growth parameter sample
}

########################################
# Box plots for fishery reference points
########################################
F_MSY_data = data.frame(F_MSY_rep)
MSY_data = data.frame(MSY_rep)
B_MSY_data = data.frame(B_MSY_rep)
Methods = c("Scales", "Otoliths", "Corroborated")
colnames(F_MSY_data) = Methods
colnames(MSY_data) = Methods
colnames(B_MSY_data) = Methods

FishRefPoints = data.frame(matrix(NA, n_rep*n_meth, 4))
colnames(FishRefPoints) = c("F_MSY", "MSY", "B_MSY", "Method")
FishRefPoints$F_MSY = melt(F_MSY_data)$value
FishRefPoints$MSY = melt(MSY_data)$value
FishRefPoints$B_MSY = melt(B_MSY_data)$value
FishRefPoints$Method = melt(F_MSY_data)$variable

Col_data = c("#E69F00", "#56B4E9", "#999999")
options(scipen=5)                             # Avoiding notation of numbers as a power of ten on the axes (i.e. no 'e-5') 

p1 <- ggplot(FishRefPoints, aes(x=Method, y=F_MSY, fill=Method)) +
  geom_boxplot(outlier.shape = NA) + #--> outliers not plotted
  xlab("Aging method") +
  ylab(expression(""~ F[MSY] ~" ["~ year^{-1} ~"]")) +
  scale_fill_manual(values=Col_data) +
  theme_bw() +
  coord_cartesian(ylim = c(0.17, 0.28)) +
  scale_y_continuous(breaks=seq(0.18, 0.28, 0.02)) +
  theme(legend.position = "none")
p2 <- ggplot(FishRefPoints, aes(x=Method, y=MSY*1e3/Bodden_area, fill=Method)) +
  geom_boxplot(outlier.shape = NA) +
  xlab("Aging method") +
  ylab(expression("MSY [kg "~ ha^-1 ~ year^{-1} ~"]")) +
  scale_fill_manual(values=Col_data) +
  coord_cartesian(ylim = c(0, 8)) +
  scale_y_continuous(breaks=seq(0, 10, 2)) +
  theme_bw() +
  theme(legend.position = "none")
p3 <- ggplot(FishRefPoints, aes(x=Method, y=B_MSY*1e3/Bodden_area, fill=Method)) +
  geom_boxplot(outlier.shape = NA) +
  xlab("Aging method") +
  ylab(expression(""~ B[MSY] ~" [kg" ~ ha^-1 ~ "]")) +
  scale_fill_manual(values=Col_data) +
  coord_cartesian(ylim = c(0, 50)) +
  theme_bw() +
  theme(legend.position = "none")

##############
# Loading Data
##############
path = "Data/SimData/MinSizeLim/"
lmin_r_vec = readRDS(file=paste0(path, "MinSizeLim.rds"))               # Scenarios of instantaneous fishing mortalities
N_vec_rep = readRDS(file=paste0(path, "N_MinSizeLim.rds"))              # Temporal average total stock size
HarvN_vec_rep = readRDS(file=paste0(path, "HarvN_MinSizeLim.rds"))      # Temporal average harvestable stock size
VulnN_vec_rep = readRDS(file=paste0(path, "VulnN_MinSizeLim.rds"))      # Temporal average stock size vulnerable to catch
TrophyN_vec_rep = readRDS(file=paste0(path, "TrophyN_MinSizeLim.rds"))  # Temporal average trophy stock size
B_vec_rep = readRDS(file=paste0(path, "B_MinSizeLim.rds"))              # Temporal average total biomass
Y_vec_rep = readRDS(file=paste0(path, "Y_MinSizeLim.rds"))              # Temporal average yield
YN_vec_rep = readRDS(file=paste0(path, "YN_MinSizeLim.rds"))            # Temporal average numeric yield
Utility_vec_rep = readRDS(file=paste0(path, "Utility_MinSizeLim.rds"))  # Temporal average yield

n_meth = dim(N_vec_rep) [3]                 # Number of different aging methods
n_rep = dim(N_vec_rep) [2]                  # Number of random samples of growth parameters per aging method
n = dim(N_vec_rep) [1]                      # Number of scenarios of minimum size limits

##########################################
# Identifying optimal minimum length limit
##########################################
MaxUtil_rep = matrix(NA, n_rep, n_meth)
MinLL_MaxUtil_rep = matrix(NA, n_rep, n_meth)

for (h in 1:n_meth){
  MaxUtil_rep[,h] = apply(Utility_vec_rep[,,h], 2, max)       # Maximum utility for each growth parameter sample
  Index_max = apply(Utility_vec_rep[,,h], 2, which.max)       # Index of Maximum utility in output metrix Utility_vec_rep[,,h] for each growth parameter sample
  MinLL_MaxUtil_rep[,h] = lmin_r_vec[Index_max]               # Optimal minimum length limit for each growth parameter sample
}

# Mean and sd of maximum utility and optimal minimum length limit from all growth parameter samples 
MaxUtil_mean_sd = rbind( colMeans(MaxUtil_rep), colSds(MaxUtil_rep) )
MinLL_MaxUtil_mean_sd = rbind( colMeans(MinLL_MaxUtil_rep), colSds(MinLL_MaxUtil_rep) )

#########################################
# Box plots for optimal min. length limit
#########################################
OptMinLL_data = data.frame(MinLL_MaxUtil_rep)
Methods = c("Scales", "Otoliths", "Corroborated")
colnames(OptMinLL_data) = Methods

OptSizeLim = data.frame(matrix(NA, n_rep*n_meth, 2))
colnames(OptSizeLim) = c("OptMinLL", "Method")
OptSizeLim$OptMinLL = melt(OptMinLL_data)$value
OptSizeLim$Method = melt(OptMinLL_data)$variable

p4 <- ggplot(OptSizeLim, aes(x=Method, y=OptMinLL/10, fill=Method)) +
  geom_boxplot(outlier.shape = NA) + # geom_boxplot(outlier.shape = NA) #--> outliers not plotted
  xlab("Aging method") +
  ylab(expression("Optimal min. length limit [cm]")) +
  scale_fill_manual(values=Col_data) +
  theme_bw() +
  #coord_cartesian(ylim = c(0.14, 0.24)) +
  theme(legend.position = "none")

if(SAVE){png("Plots/FishRefPoints_OptMinLL_Boxplots.png", width = 4000, height = 3400, res=600)}

(p1 + p2) /
(p3 + p4) + plot_annotation(tag_levels = "a")

if(SAVE){dev.off()}

aggregate(FishRefPoints[, 1:3], list(FishRefPoints$Method), median)
aggregate(FishRefPoints[, 1:3], list(FishRefPoints$Method), mean)
aggregate(OptSizeLim[, 1], list(OptSizeLim$Method), median)
aggregate(OptSizeLim[, 1], list(OptSizeLim$Method), mean)
```

```{r pike age model & figure 8, include=FALSE, eval=FALSE}
####################################################################################
# Pike model: Effect of different age reading methods on fishery reference points  
# Code author: Elias Ehrlch           
####################################################################################

setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to source file (for using RStudio)

#############################
# Load Packages and functions
#############################
library(matrixStats)
library(reshape2)
library(ggplot2)
library(patchwork)

#########
# Setting
#########
SAVE = 0                  # Set to 1 to save png plot and to 0 if not

##############
# Loading Data
##############
#source("AgePikeModel_Parameters.R") # Import parameters

path = "Data/SimData/FishRefPoints/"
F_mort_vec = readRDS(file=paste0(path, "F_mort.rds"))               # Scenarios of instantaneous fishing mortalities
N_vec_rep = readRDS(file=paste0(path, "N_F_mort.rds"))              # Temporal average total stock size
HarvN_vec_rep = readRDS(file=paste0(path, "HarvN_F_mort.rds"))      # Temporal average harvestable stock size
VulnN_vec_rep = readRDS(file=paste0(path, "VulnN_F_mort.rds"))      # Temporal average stock size vulnerable to catch
TrophyN_vec_rep = readRDS(file=paste0(path, "TrophyN_F_mort.rds"))  # Temporal average trophy stock size
AmountTrophy_vec_rep = readRDS(file=paste0(path, "AmountTrophy_F_mort.rds"))  # Temporal average amount of trophy fish in population
B_vec_rep = readRDS(file=paste0(path, "B_F_mort.rds"))              # Temporal average total biomass
Y_vec_rep = readRDS(file=paste0(path, "Y_F_mort.rds"))              # Temporal average yield
YN_vec_rep = readRDS(file=paste0(path, "YN_F_mort.rds"))            # Temporal average yield

n_meth = dim(N_vec_rep) [3]                 # Number of different aging methods
n_rep = dim(N_vec_rep) [2]                  # Number of random samples of growth parameters per aging method
n = dim(N_vec_rep) [1]                      # Number of scenarios of F

########################################
# Calculating fisheries reference points
########################################
# Fishery reference points for each random sample of growth parameters for the n_meth=3 aging methods
MSY_rep = matrix(NA, n_rep, n_meth)
F_MSY_rep = matrix(NA, n_rep, n_meth)
B_MSY_rep = matrix(NA, n_rep, n_meth)
N_MSY_rep = matrix(NA, n_rep, n_meth)
HarvN_MSY_rep = matrix(NA, n_rep, n_meth)
VulnN_MSY_rep = matrix(NA, n_rep, n_meth)
TrophyN_MSY_rep = matrix(NA, n_rep, n_meth)

YNmax_rep = matrix(NA, n_rep, n_meth) 

# my.max <- function(x) ifelse( !all(is.na(x)), max(x, na.rm=T), NA) # if every (all) element in x is NA, then NA is returned, and the max otherwise

for (h in 1:n_meth){
  MSY_rep[,h] = apply(Y_vec_rep[,,h], 2, max)                 # MSY (=highest temporal mean yield over all scenarios) for each growth parameter sample
  Index_max = apply(Y_vec_rep[,,h], 2, which.max)             # Index of MSY in output metrix Y_vec_rep[,,h] for each growth parameter sample
  F_MSY_rep[,h] = F_mort_vec[Index_max]                       # F_MSY for each growth parameter sample
  for (j in 1:n_rep){
    B_MSY_rep[j,h] = B_vec_rep[Index_max[j],j,h]              # B_MSY for each growth parameter sample
    N_MSY_rep[j,h] = N_vec_rep[Index_max[j],j,h]              # N_MSY for each growth parameter sample
    HarvN_MSY_rep[j,h] = HarvN_vec_rep[Index_max[j],j,h]  
    VulnN_MSY_rep[j,h] = VulnN_vec_rep[Index_max[j],j,h]  
    TrophyN_MSY_rep[j,h] = TrophyN_vec_rep[Index_max[j],j,h]
  }
  YNmax_rep[,h] = apply(YN_vec_rep[,,h], 2, max)              # Maximum number of harvested fish for each growth parameter sample
}

#################################
# Plots of output metrices over F
#################################
# Function to provide 25% quantile, mean, and 75 % qantile
MeanIQR <- function(Data){
  c(round(mean(Data),4), round(quantile(Data, prob=.25),4), round(quantile(Data, prob=.75),4) )
}

N_mean_IQR = array(NA, dim=c(n, 3, n_meth))                      # Average stock size (Quantiles and mean for all growth parameter samples)
HarvN_mean_IQR = array(NA, dim=c(n, 3, n_meth))                  # Average harvestable stock size (Quantiles and mean for all growth parameter samples)
VulnN_mean_IQR = array(NA, dim=c(n, 3, n_meth))                  # Average stock size vulnerable to catch (Quantiles and mean for all growth parameter samples)
TrophyN_mean_IQR = array(NA, dim=c(n, 3, n_meth))                # Average trophy stock size (Quantiles and mean for all growth parameter samples)
AmountTrophy_mean_IQR = array(NA, dim=c(n, 3, n_meth))           # Average amount of trophy fish in population (Quantiles and mean for all growth parameter samples)
B_mean_IQR = array(NA, dim=c(n, 3, n_meth))                      # Average stock biomass (Quantiles and mean for all growth parameter samples)
Y_mean_IQR = array(NA, dim=c(n, 3, n_meth))                      # Average yield (Quantiles and mean for all growth parameter samples)
YN_mean_IQR = array(NA, dim=c(n, 3, n_meth))                     # Average numeric yield (Quantiles and mean for all growth parameter samples)

for(h in 1:n_meth){
  for(i in 1:n){
    N_mean_IQR[i,,h] = MeanIQR(N_vec_rep[i,,h])                   # Quantiles and mean of average stock size [ind.]
    HarvN_mean_IQR[i,,h] = MeanIQR(HarvN_vec_rep[i,,h])           # Quantiles and mean of average harvestable stock size [ind.]
    VulnN_mean_IQR[i,,h] = MeanIQR(VulnN_vec_rep[i,,h])           # Quantiles and mean of average harvestable stock size [ind.]
    TrophyN_mean_IQR[i,,h] = MeanIQR(TrophyN_vec_rep[i,,h])       # Quantiles and mean of average trophy stock size [ind.]
    AmountTrophy_mean_IQR[i,,h] = MeanIQR(AmountTrophy_vec_rep[i,,h])       # Quantiles and mean of average amount of trophy fish in population []
    B_mean_IQR[i,,h] = MeanIQR(B_vec_rep[i,,h])                   # Quantiles and mean of average stock biomass [t]
    Y_mean_IQR[i,,h] = MeanIQR(Y_vec_rep[i,,h])                   # Quantiles and mean of average yield [t year^-1]
    YN_mean_IQR[i,,h] = MeanIQR(YN_vec_rep[i,,h])                 # Quantiles and mean of average numeric yield [Ind. year^-1]
  }
}

# Plot settings
ggbg <- function() {                          # for background and grid color of plot
  points(0, 0, pch=16, cex=1e6, col="white")
  grid(col="gray95", lty=1)
}

fontsize_lab = 1.4
fontsize_axis = 1.2
linewidth = 2.0
pointsize = 1.5
Col_data = c("#E69F00", "#56B4E9", "grey35")
Col_IQR = adjustcolor(Col_data, alpha.f = 0.2)
AreaDensLine = c(NA, NA, 35)
AreaAngleLine = c(NA, NA, 90)
subplot_labels = c("a", "b", "c")

# Values and labels of plot axes for two different size limits (x-axis) and three different output metrices (y-axis), respectively
ScalingN = 1e5
Xlab = expression("Fishing mortality [" ~ year^{-1} ~"]")
Yax = c(parse(text="Y_mean_IQR*1e3/Bodden_area"), parse(text="B_mean_IQR*1e3/Bodden_area"), parse(text="AmountTrophy_mean_IQR"))
Ylab = c(expression("Yield [kg" ~ ha^-1 ~ year^{-1} ~ "]"), expression("Biomass [kg" ~ ha^-1 ~ "]"), expression("Amount of fish">="1m"))
#Y_F_MSY = c(parse(text="MSY"), parse(text="B_MSY"), parse(text="TrophyN_MSY"))

# Plotting function - plot output metrics 'Y' (= Yield, Biomass or Number of trophy fish)
Plot_func <- function(x, yax, F_MSY, Xlab, Ylab, panel, Col_data, Col_IQR, AreaDensLine, AreaAngleLine, linewidth, pointsize, fontsize_lab, fontsize_axis, subplot_label, LEGEND){
  # -> Scales - mean and IQR
  matplot(x, yax[,1,1], xlab=Xlab, ylab=Ylab, panel.first=panel, col=Col_data[1], type='l',
          lty=1, lwd=linewidth, cex.lab=fontsize_lab, cex.axis=fontsize_axis, ylim=c(0,max(yax)))
  polygon(c(x, rev(x)), c(yax[,3,1], rev(yax[,2,1])), col=Col_IQR[1], density = AreaDensLine[1], angle = AreaAngleLine[1], border=NA)
  # -> Otoliths - mean and IQR
  points(x, yax[,1,2], type='l',  lty=1, lwd=linewidth, col=Col_data[2])
  polygon(c(x,rev(x)),c(yax[,3,2],rev(yax[,2,2])),col=Col_IQR[2], density = AreaDensLine[2], angle = AreaAngleLine[2], border=NA)
  # -> Corroborated age - mean and IQR
  points(x, yax[,1,3], type='l',  lty=1, lwd=linewidth, col=Col_data[3])
  polygon(c(x,rev(x)),c(yax[,3,3],rev(yax[,2,3])),col=Col_IQR[3], density = AreaDensLine[3], angle = AreaAngleLine[3], border=NA)
  
  # for (nn in 1:3){
  #   segments(F_MSY[nn],0,F_MSY[nn],y_F_MSY[nn],col=Col_data[nn],lty=2)
  #   points(F_MSY[nn],y_F_MSY[nn],col=Col_data[nn],pch=16,cex=pointsize)         # adding reference point for (F_MSY, MSY)
  # }

  mtext(subplot_label, adj=-0.27, line=-0.1)
  
  if(LEGEND==T) { legend("topright",c("Scales", "Otoliths", "Corroborated"), lty=1, col=Col_data)}
}

# Plotting - min, mean and max of model output (if no cycles, all 3 appearing as one line)
if(SAVE){png("Plots/Curves_YieldBiomTrophy_vs_F.png", width = 6000, height = 1800, res=600)}
par(mfrow=c(1,3),mar=c(4,5,1,1)) #,bty="n")

for(pp in 1:length(Yax)){
  yax = eval(Yax[pp])
  if(pp == 2){LEGEND = T} else{LEGEND = F}
  Plot_func(F_mort_vec, yax, F_MSY[1,], Xlab, Ylab[pp], ggbg(), Col_data, Col_IQR, AreaDensLine, AreaAngleLine, linewidth, pointsize, fontsize_lab, fontsize_axis, subplot_labels[pp], LEGEND)
}

if(SAVE){dev.off()}
```
