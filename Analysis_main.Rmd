---
title: "Analysis pike age corroboration"
author: "TR"
date: "`r Sys.Date()`"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

**All code chunks except for figures used in the publication have "eval=FALSE" set in options, to avoid running the whole script every time a document is knitted. In order to run an indvidual code chunk, change options "eval=FALSE" to "eval=TRUE"**

```{r packages, include=FALSE}
library(here)
library(ggplot2)
library(tidyverse)
library(foreign)
library(lubridate)
library(car)
library(FSA)
library(flextable)
library(lme4)
library(ggpubr)
library(tidymodels)
library(nlstools)
library(bayesplot)
library(RColorBrewer)
library(loo)
library("rstan")
options(mc.cores = parallel::detectCores())
rstan_options(auto_write = TRUE)
library(sjPlot)
```

## 3.1. Expected $\delta^{18}$O values in otolith aragonite
```{r moddeledd18Otest, echo=FALSE, include=FALSE, warning=FALSE, eval=FALSE}
rm(list = ls())

MonthsBodden <- read.delim("Data/Mean-TS_lagoons.txt", header = T, 
                           stringsAsFactors = F, sep = "\t", dec = ".")
Months_GB <- read.delim("Data/Mean-TS_GB.txt", header = T, 
                           stringsAsFactors = F, sep = "\t", dec = ".")
Months_NRB <- read.delim("Data/Mean-TS_NRB.txt", header = T, 
                           stringsAsFactors = F, sep = "\t", dec = ".")
Months_WRB <- read.delim("Data/Mean-TS_WRB.txt", header = T, 
                           stringsAsFactors = F, sep = "\t", dec = ".")
Aragonite_prediction <- read.delim("Data/Predicted_otolith_d18O.txt", header = T, 
                           stringsAsFactors = F, sep = "\t", dec = ".")

# Join data from all lagoon areas
MonthsBodden <- rbind(Months_GB, Months_NRB, Months_WRB)

# Test for significant differences between surface and bottom temperature
modeldepth <- lm(temperature~depth, data = MonthsBodden)
anova(modeldepth)

# Transform prediction table to long format
shorecompare <- Aragonite_prediction%>%
  pivot_longer(cols = c(temperature_shore, temperature_open), 
               names_to = "open_shore", values_to = "Temp")%>%
  transmute(month = month,
            date = date,
            site = case_when(open_shore %in% "temperature_shore" ~ "S",
                             open_shore %in% "temperature_open" ~"O"),
            temp = Temp)

# Test for differences in shore vs open lagoon temperature  
modelshore <- lm(temp~site, data = shorecompare)
anova(modelshore)

# Function to center values
center_scale <- function(x){
  scale(x, scale = F)
}

# Center Temperature & isotope measurements
Aragonite_prediction$Tcenter <- center_scale(Aragonite_prediction$temperature_open)
Aragonite_prediction$Dcenter <- center_scale(Aragonite_prediction$d18O_station)

# Mixed linear models for equation 1 (Patterson et al.)
# Base model
mR <- lmer(Prediction_Patterson_WRB_VPDB~Dcenter+Tcenter+(1|month), data = Aragonite_prediction)

# Test significance of random effect month
rand(mR)

# Maximum likelihood estimation for significance testing
mR <- lmer(Prediction_Patterson_WRB_VPDB~Dcenter+Tcenter+(1|month), data = Aragonite_prediction, REML = F)

# Model without Temperature
m1.1 <- lmer(Prediction_Patterson_WRB_VPDB~Dcenter+(1|month), data = Aragonite_prediction, REML = F)

# Model without isotope measurements
m1.2 <- lmer(Prediction_Patterson_WRB_VPDB~Tcenter+(1|month), data = Aragonite_prediction, REML = F)

anova(mR, m1.1) #Temperature significant
anova(mR, m1.2) #d18O significant

# Mixed linear models for equation 1 (Geffen et al.)
# Base model
mR2 <- lmer(Prediction_Geffen_WRB_VPDB~Dcenter+Tcenter+(1|month), data = Aragonite_prediction)

# Test significance of random effect month
rand(mR2)

# Maximum likelihood estimation for significance testing
mR2 <- lmer(Prediction_Geffen_WRB_VPDB~Dcenter+Tcenter+(1|month), data = Aragonite_prediction, REML = F)

# Model without Temperature
m2.1 <- lmer(Prediction_Geffen_WRB_VPDB~Dcenter+(1|month), data = Aragonite_prediction, REML = F)

# Model without isotope measurements
m2.2 <- lmer(Prediction_Geffen_WRB_VPDB~Tcenter+(1|month), data = Aragonite_prediction, REML = F)

anova(mR2, m2.1) #Temperature significant
anova(mR2, m2.2) #d18O significant

# Re-run final models with REML
Model.final.P <- lmer(Prediction_Patterson_WRB_VPDB~Dcenter+Tcenter+(1|month), data = Aragonite_prediction)
Model.final.G <- lmer(Prediction_Geffen_WRB_VPDB~Dcenter+Tcenter+(1|month), data = Aragonite_prediction)

# Assess summary
summary(Model.final.P)
summary(Model.final.G)

# Produce summary table
tab_model(Model.final.G, digits.re = 20)
```

```{r sensitivity & range, include=FALSE, eval=FALSE}
# Code for sensitivity & range calculations of d18O prediction equations
alpha = exp((18.56*1000*((20+273.15)^-1)-33.49)/1000)
(0.97001*(alpha*(1000-6.5)-1000)-29.99) - (0.97001*(alpha*(1000-6.5+sd(Aragonite_prediction$d18O_station))-1000)-29.99)

alpha = exp((15.99*1000*((20+273.15)^-1)-24.25)/1000)
(0.97001*(alpha*(1000-6.5)-1000)-29.99) - (0.97001*(alpha*(1000-6.5+sd(Aragonite_prediction$d18O_station))-1000)-29.99)

alpha = exp((18.56*1000*((20+273.15)^-1)-33.49)/1000)
alpha2 = exp((18.56*1000*((20+sd(Aragonite_prediction$temperature_open)+273.15)^-1)-33.49)/1000)
(0.97001*(alpha*(1000-6.5)-1000)-29.99) - (0.97001*(alpha2*(1000-6.5)-1000)-29.99)

alpha = exp((15.99*1000*((20+273.15)^-1)-24.25)/1000)
alpha2 = exp((15.99*1000*((20+sd(Aragonite_prediction$temperature_open)+273.15)^-1)-24.25)/1000)
(0.97001*(alpha*(1000-6.5)-1000)-29.99) - (0.97001*(alpha2*(1000-6.5)-1000)-29.99)

range(Aragonite_prediction$d18O_station)
range(Aragonite_prediction$temperature_open)

alpha = exp((18.56*1000*((15+273.15)^-1)-33.49)/1000)
alpha2 = exp((18.56*1000*((4+273.15)^-1)-33.49)/1000)
(0.97001*(alpha*(1000-5.3)-1000)-29.99) - (0.97001*(alpha2*(1000-5.3)-1000)-29.99)

(0.97001*(alpha*(1000-6.5)-1000)-29.99) - (0.97001*(alpha*(1000-6.5+(-4.2+6.5))-1000)-29.99)
```

```{r Figure 2 modelled d18O, echo=FALSE, dpi=600, message=F, warning=F}
rm(list = ls())

Aragonite_prediction <- read.delim("Data/Predicted_otolith_d18O.txt", header = T, 
                           stringsAsFactors = F, sep = "\t", dec = ".")

Aragonite_prediction$date <- lubridate::date(parse_date_time(Aragonite_prediction$date, orders = c("ymd")))

text_2020 <- text_grob("2020", size = 15)
text_2021 <- text_grob("2021", size = 15)
  
ggplot(Aragonite_prediction)+
  geom_line(aes(date, Prediction_Patterson_WRB_VPDB), color = "black", size = 1)+
  geom_point(aes(date, Prediction_Patterson_WRB_VPDB, shape = "Equation 1"), size = 3)+
  geom_line(aes(date, Prediction_Geffen_WRB_VPDB), color = "black", size = 1)+
  geom_point(aes(date, Prediction_Geffen_WRB_VPDB, shape = "Equation 2"), size = 3)+
  scale_y_continuous(limits = c(-6,-1.5), breaks = seq(-6, -1.5, .5))+
    coord_cartesian(clip = "off")+
  annotation_custom(text_2020, xmin = as.Date("2020-04-13"), xmax = as.Date("2020-04-13"), ymin = -8,ymax = -7)+  
  annotation_custom(text_2021, xmin = as.Date("2021-01-27"), xmax = as.Date("2021-01-27"), ymin = -8,ymax = -7)+
    scale_x_date(date_breaks = "1 month", 
                 date_labels = c("Mar", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec", "Jan", "Feb"))+
    scale_shape_manual(name = "", breaks = c("Equation 1", "Equation 2"), values = c(15, 17))+
  ylab(expression(atop(delta^18*"O"~"modelled aragonite", ("VPDB \u2030"))))+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(),
        panel.grid.major.x = element_line(size = .5, colour = "grey", linetype = 2),
        axis.line = element_line(size = 1, colour = "black", linetype = 1), axis.title.y = element_text(size = 15),
        axis.ticks= element_line(size = 2), axis.text.y = element_text(size = 15, colour = "black"),
        axis.text.x = element_text(size = 15, colour = "black", angle = 90), axis.ticks.x = element_line(size = 2), 
        axis.title.x = element_text(size = 15, colour = "white"),
        legend.position = "bottom", legend.text = element_text(size = 15), legend.title = element_text(size = 15))

```

## 3.2. Obtaining a corroborated age estimation
```{r establish reference, include=FALSE}
#Script for precision, accuracy metrics and bias plots of corroborated ages

rm(list = ls())

#Read data
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

#join
pikedata <- pikedata%>%
  transmute(id = id,
            Age_refAuto = age_ref,
            Age_refT = age_comb,
            Age_refC = age_combC)%>%
  distinct()

#Precision for combined images
AP_ref_compare <- agePrecision(~Age_refT + Age_refC, data = pikedata)
summary(AP_ref_compare, what = "precision")

#Bias for combined images, second argument is reference age
AB_ref_compare <- ageBias(Age_refT~Age_refC, data = pikedata, ref.lab = "comboT",
                            nref.lab = "comboC")
summary(AB_ref_compare)

#Precision for automated age
AP_auto_combo <- agePrecision(~Age_refAuto + Age_refT, data = pikedata)
AP_auto_comboC <- agePrecision(~Age_refAuto + Age_refC, data = pikedata)
summary(AP_auto_combo, what = "precision")
summary(AP_auto_comboC, what = "precision")

#Bias for automated age
ab_auto_combo <- ageBias(Age_refT ~ Age_refAuto, data = pikedata, ref.lab = "Auto", 
                         nref.lab = "comboT")

ab_auto_comboC <- ageBias(Age_refC ~ Age_refAuto, data = pikedata, ref.lab = "Auto", 
                    nref.lab = "comboC")

summary(ab_auto_combo)
summary(ab_auto_comboC)

save(AP_ref_compare, AB_ref_compare, AP_auto_comboC, AP_auto_combo, ab_auto_comboC, ab_auto_combo, file="Data/Refcompare.RData")

```

```{r Figure 4 Reference age comparison, echo=FALSE, dpi=600, message=F, warning=F}

rm(list = ls())

load("Data/Refcompare.RData")

Refcompare <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 2) +
  geom_errorbar(data = ab_auto_combo$bias.diff, 
                aes(x=Age_refAuto,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_errorbar(data = ab_auto_comboC$bias.diff, 
                aes(x=Age_refAuto,ymin=LCI,ymax=UCI,color=sig), width = 0, color = "blue")+
  geom_point(data = ab_auto_combo$bias.diff, 
             aes(x=Age_refAuto, y=mean, color=sig, fill=sig),shape=21, size = 2)+
  geom_point(data = ab_auto_comboC$bias.diff, 
             aes(x=Age_refAuto, y=mean, color=sig, fill=sig),shape=18, size = 3, color = "blue")+
  geom_smooth(data=ab_auto_combo$data,aes(x=Age_refAuto,y=diff),size=.65, color = "blue")+
  geom_smooth(data=ab_auto_comboC$data,aes(x=Age_refAuto,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("reader age - automated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(), panel.grid.major = element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 15), 
        axis.text = element_text(colour = "black", size = 15))

Refcompare

```


## 3.3. Aging accuracy and bias of otoliths and scales
```{r agebias, include=FALSE}
# Script for age precision, accuracy and bias metrics & plots

rm(list = ls())

# load data
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

#Explanation of columns:
# age_ref: Reference age (automated age counter)
# age_comb: Reader 1 corroboration age (otoliths + overplotted d18O)
# age_combC: Reader 3 corroboration age (otoliths + overplotted d18O)
# age_otoT: Reader 1 visual otolith age estimation
# age_otoK: Reader 2 visual otolith age estimation
# age_scaleT: Reader 1 visual scale age estimation
# age_scaleK: Reader 2 visual scale age estimation
# mrad.comb: otolith radius at last increment
# trad.comb: otolith total radius
# Length_LI: Length at last increment (backcalculation routine below)

pikedata <- pikedata%>%
  transmute(id = id,
            TL = TL,
            Age = age_ref,
            date = date)
# Age precision metrics
AP_scale1_ref <- agePrecision(~age_scaleT + age_ref, data = pikedata)
AP_scaleK_ref <- agePrecision(~age_scaleK + age_ref, data = pikedata)
AP_oto1_ref <- agePrecision(~age_otoT + age_ref, data = pikedata)
AP_otoK_ref <- agePrecision(~age_otoK + age_ref, data = pikedata)

summary(AP_scale1_ref, what = "precision")
summary(AP_scaleK_ref, what = "precision")
summary(AP_oto1_ref, what = "precision")
summary(AP_otoK_ref, what = "precision")

# Signed rank test for CVs
# Reader 1
Structure_vs_ref1 <- data.frame("ID" = pikedata$id, "CVOto" = AP_oto1_ref$detail$CV,
                    "CVScales1" = AP_scale1_ref$detail$CV)
Structure_vs_ref1 <- Structure_vs_ref1 %>% pivot_longer(!ID, names_to = "structure", values_to = "CV")
Structure_vs_ref1$structure <- sub("CVOto", "Oto", Structure_vs_ref1$structure)
Structure_vs_ref1$structure <- sub("CVScales1", "Scales", Structure_vs_ref1$structure)

CVTest1 <- wilcox.test(CV~structure, Structure_vs_ref1)

Structure_vs_refK <- data.frame("ID" = pikedata$id, "CVOto" = AP_otoK_ref$detail$CV,
                    "CVScales1" = AP_scaleK_ref$detail$CV)
Structure_vs_refK <- Structure_vs_refK %>% pivot_longer(!ID, names_to = "structure", values_to = "CV")
Structure_vs_refK$structure <- sub("CVOto", "Oto", Structure_vs_refK$structure)
Structure_vs_refK$structure <- sub("CVScales1", "Scales", Structure_vs_refK$structure)

CVTestK <- wilcox.test(CV~structure, Structure_vs_refK)

CVTest1
CVTestK

#Agebias
ab_scale1_ref <- ageBias(age_scaleT ~ age_ref, data = pikedata, 
                        ref.lab = "ref", nref.lab = "scales2")
ab_scaleK_ref <- ageBias(age_scaleK ~ age_ref, data = pikedata, 
                        ref.lab = "ref", nref.lab = "scalesK")
ab_oto1_ref <- ageBias(age_otoT ~ age_ref, data = pikedata, 
                        ref.lab = "ref", nref.lab = "otoT")
ab_otoK_ref <- ageBias(age_otoK ~ age_ref, data = pikedata, 
                        ref.lab = "ref", nref.lab = "otoK")

summary(ab_scale1_ref, flip.table = T)
summary(ab_scale1_ref, what = "symmetry")
summary(ab_scale1_ref, what = "bias")

summary(ab_scaleK_ref, flip.table = T)
summary(ab_scaleK_ref, what = "symmetry")
summary(ab_scaleK_ref, what = "bias")

summary(ab_oto1_ref, flip.table = T)
summary(ab_oto1_ref, what = "symmetry")
summary(ab_oto1_ref, what = "bias")

summary(ab_otoK_ref, flip.table = T)
summary(ab_otoK_ref, what = "symmetry")
summary(ab_otoK_ref, what = "bias")

# Save data
save(AP_oto1_ref, AP_otoK_ref, AP_scale1_ref, AP_scaleK_ref, ab_oto1_ref, ab_otoK_ref, ab_scale1_ref, ab_scaleK_ref, file="Data/AgeBias.RData")
```

```{r agebiastests, include=FALSE}
rm(list = ls())

# load data
load("Data/AgeBias.RData")
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

# Age precision metrics

summary(ab_scale1_ref, flip.table = T)
summary(ab_scale1_ref, what = "symmetry")
summary(ab_scale1_ref, what = "bias")

summary(ab_scaleK_ref, flip.table = T)
summary(ab_scaleK_ref, what = "symmetry")
summary(ab_scaleK_ref, what = "bias")

summary(ab_oto1_ref, flip.table = T)
summary(ab_oto1_ref, what = "symmetry")
summary(ab_oto1_ref, what = "bias")

summary(ab_otoK_ref, flip.table = T)
summary(ab_otoK_ref, what = "symmetry")
summary(ab_otoK_ref, what = "bias")


summary(AP_scale1_ref, what = "precision")
summary(AP_scaleK_ref, what = "precision")
summary(AP_oto1_ref, what = "precision")
summary(AP_otoK_ref, what = "precision")

# Signed rank test for CVs
# Reader 1
Structure_vs_ref1 <- data.frame("ID" = pikedata$id, "CVOto" = AP_oto1_ref$detail$CV,
                    "CVScales1" = AP_scale1_ref$detail$CV)
Structure_vs_ref1 <- Structure_vs_ref1 %>% pivot_longer(!ID, names_to = "structure", values_to = "CV")
Structure_vs_ref1$structure <- sub("CVOto", "Oto", Structure_vs_ref1$structure)
Structure_vs_ref1$structure <- sub("CVScales1", "Scales", Structure_vs_ref1$structure)

CVTest1 <- wilcox.test(CV~structure, Structure_vs_ref1)

# Reader 2
Structure_vs_refK <- data.frame("ID" = pikedata$id, "CVOto" = AP_otoK_ref$detail$CV,
                    "CVScales1" = AP_scaleK_ref$detail$CV)
Structure_vs_refK <- Structure_vs_refK %>% pivot_longer(!ID, names_to = "structure", values_to = "CV")
Structure_vs_refK$structure <- sub("CVOto", "Oto", Structure_vs_refK$structure)
Structure_vs_refK$structure <- sub("CVScales1", "Scales", Structure_vs_refK$structure)

CVTestK <- wilcox.test(CV~structure, Structure_vs_refK)
```

```{r Table 1 age bias, echo=FALSE,message=FALSE,warning=FALSE,error=FALSE}

rm(list = ls())

load("Data/AgeBias.RData")

Overview_agebias <- cbind(rbind(summary(AP_scale1_ref, what = "precision"),
                                summary(AP_scaleK_ref, what = "precision"),
                                summary(AP_oto1_ref, what = "precision"),
                                summary(AP_otoK_ref, what = "precision")),
                          rbind(summary(AP_scale1_ref, what = "absolute",,3),
                                summary(AP_scaleK_ref, what = "absolute",,3), 
                                summary(AP_oto1_ref, what = "absolute",,3),
                                summary(AP_otoK_ref, what = "absolute",,3)))

Overview_agebias$sample <- c("Reader 1 scale age",  "Reader 2 scale age", 
                             "Reader1 otolith age", "Reader 2 otolith age")

Overview_agebias <- data.frame(Overview_agebias)
Overview_agebias$X1 <- Overview_agebias$X1 + Overview_agebias$X0
Overview_agebias$X2 <- Overview_agebias$X1 + Overview_agebias$X2

Overview_agebias[,c(3:11)] <- round(Overview_agebias[,c(3:11)], 1)
Overview_agebias$PercAgree <- paste(Overview_agebias$PercAgree, "%")
Overview_agebias$X1 <- paste(Overview_agebias$X1, "%")
Overview_agebias$X2 <- paste(Overview_agebias$X2, "%")

Overview <- flextable(Overview_agebias, col_keys = c("sample", "validn", "PercAgree","X1",
                                                     "X2", "ACV", "AAD", "APE"))%>%
  fontsize(part = "all", size = 10)%>%
  bold(part = "header")%>%
  set_header_labels(sample = "Structure", 
                    validn = "N", 
                    PercAgree = "% agreement",
                    X1 = "\u00B1 1 year", 
                    X2 = "\u00B1 2 years", 
                    ASD = "Average standard deviation",
                    ACV = "Average coefficient of variation [%]", 
                    AAD = "Average absolute deviation", 
                    APE = "Average percent error [%]")%>%
  set_caption("Summary of aging precision and accuracy metrics")%>%
  colformat_double(j = "ACV", suffix = "%")%>%
  colformat_double(j = "APE", suffix = "%")%>%
  colformat_double(j = "PercAgree", suffix = "%")%>%
  colformat_double(j = "X1", suffix = "%")%>%
  colformat_double(j = "X2", suffix = "%")%>%
  set_table_properties(layout = "autofit")

Overview
```

```{r Figure 5 agebiasplots, echo=FALSE, message=FALSE, warning=FALSE, error=FALSE, fig.height=6, fig.width=6, dpi=600}

rm(list = ls())

load("Data/AgeBias.RData")

#Otoliths Timo
a <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 1) +
  geom_errorbar(data = ab_oto1_ref$bias.diff, 
                aes(x=age_ref,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_point(data = ab_oto1_ref$bias.diff, 
             aes(x=age_ref, y=mean, color=sig, fill=sig),shape=21, size = 2) +
  geom_smooth(data=ab_oto1_ref$data,aes(x=age_ref,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("otolith age - corroborated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(), 
        panel.grid.major = element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 10), 
        axis.text = element_text(colour = "black", size = 10))

#Otoliths Korbi
b <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 1) +
  geom_errorbar(data = ab_otoK_ref$bias.diff, 
                aes(x=age_ref,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_point(data = ab_otoK_ref$bias.diff, 
             aes(x=age_ref, y=mean, color=sig, fill=sig),shape=21, size = 2) +
  geom_smooth(data=ab_otoK_ref$data,aes(x=age_ref,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("otolith age - corroborated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(), 
        panel.grid.major = element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 10), 
        axis.text = element_text(colour = "black", size = 10))

#Scales Timo
c <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 1) +
  geom_errorbar(data = ab_scale1_ref$bias.diff, 
                aes(x=age_ref,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_point(data = ab_scale1_ref$bias.diff, 
             aes(x=age_ref, y=mean, color=sig, fill=sig),shape=21, size = 2) +
  geom_smooth(data=ab_scale1_ref$data,aes(x=age_ref,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("scale age - corroborated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(),
        panel.grid.major = element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 10), 
        axis.text = element_text(colour = "black", size = 10))

#Scales Korbi
d <- ggplot() +
  geom_hline(yintercept=0,linetype="dashed",color="darkgrey", size = 1) +
  geom_errorbar(data = ab_scaleK_ref$bias.diff, 
                aes(x=age_ref,ymin=LCI,ymax=UCI,color=sig), width = 0)+
  geom_point(data = ab_scaleK_ref$bias.diff, 
             aes(x=age_ref, y=mean, color=sig, fill=sig),shape=21, size = 2) +
  geom_smooth(data=ab_scaleK_ref$data,aes(x=age_ref,y=diff),size=.65, color = "black")+
  scale_fill_manual(values=c("black","white"),guide="none") +
  scale_color_manual(values=c("black","red3"),guide="none") +
  scale_x_continuous(breaks=0:15) +
  scale_y_continuous(limits = c(-6,4), breaks=c(-6:4))+
  ylab("scale age - corroborated age")+
  xlab("corroborated age")+
  theme(panel.background = element_blank(), 
        panel.grid.major =  element_line(colour = "grey", linetype = "dotted"),
        panel.border = element_rect(colour = "black", fill = NA),
        axis.line = element_line(colour = "black", size = 1),
        axis.title = element_text(colour = "black", size = 10), 
        axis.text = element_text(colour = "black", size = 10))

plots <- ggarrange(a, b, c, d, ncol = 2, nrow = 2, 
                    labels = c("A", "B", "C", "D"), label.x = 0.9, font.label = list(size = 15))

plots
```

## 3.4. Population-level growth of pike using age data from different aging structures
```{r Fraser Lee Backcalculation, include=FALSE, eval=FALSE}

# Script to convert length at capture to length at last increment using Fraser Lee equation

rm(list = ls())

# Read age data with radii
pikedata <- read.delim("Data/Pike_ages_all_with_TL.txt", header = T, 
                       stringsAsFactors = F)

# Visual examination
ggplot(pikedata, aes(log(trad_comb), log(TL))) + geom_point() + theme_minimal()
ggplot(pikedata, aes(trad_comb, TL)) + geom_point() + theme_minimal()

# Linear model of length at capture vs otolith radius at last increment
lmOto <- lm(TL~trad_comb, data = pikedata)
loglmOto <- lm(log(TL)~log(trad_comb), data = pikedata)
summary(lmOto)
summary(loglmOto)

# Extract coefficients for Backcalculation
a <- coefficients(loglmOto)[[1]]
b <- coefficients(loglmOto)[[2]]

# Add column with backcalculated lengths
pikedata <- pikedata %>%
  mutate(Length_LI = exp(log(TL)+b*(log(mrad_comb)-log(trad_comb))))
pikedata$Length_LI <- ifelse(pikedata$month <= 4, pikedata$TL, pikedata$Length_LI)

# Save table in data
write.table(pikedata, "Data/Pike_ages_all_with_TL_backcalulated.txt", sep = "\t", 
            dec = ".", row.names = F)
```

```{r growth model multimodel comparison, include=FALSE}
# Script to compare prior constellations for growth models

rm(list = ls())

# Load pike data
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

# Load list of priors (fishbase credible estimates, as of database version December 2021)
priors <- read.delim("Data/Priors_pike.csv", sep = ";", header = T, stringsAsFactors = F)

# Transform mm to cm
pikedata$age_oto <- round(rowMeans(pikedata[,c("age_otoT", "age_otoK")]),0)
pikedata$age_scale <- round(rowMeans(pikedata[,c("age_scaleT", "age_scaleK")]),0)
pikedata <- pikedata %>% filter(area != "KD")

# Cleanup
growthdata <- pikedata %>%
  transmute(id = id,
            sex = sex,
            weight = weight,
            TL = TL/10,
            L = Length_LI/10,
            date = date,
            area = area,
            age_ref = age_ref,
            age_oto = age_oto,
            age_scale = age_scale)

# Write data lists for stan
#Variance at 10% mean
standata_ref_1 = list(
  Length = growthdata$L,
  Age = growthdata$age_ref,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/10,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

#Variance at 5% mean
standata_ref_2 = list(
  Length = growthdata$L,
  Age = growthdata$age_ref,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/20,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

#Only error structure
standata_ref_3 = list(
  Length = growthdata$L,
  Age = growthdata$age_ref,
  N = nrow(growthdata),
  linf_mean = 0, #alt: mean^2/variance & variance/mean
  linf_var = 150,
  t0_mean = 0,
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

# Stan Code path
stancode1 <- "Stan/Simple_VBGF_TZero.stan"

# Fit models
fit_ref_1 = stan(stancode1, iter = 10000, data = standata_ref_1)
fit_ref_2 = stan(stancode1, iter = 10000, data = standata_ref_2)
fit_ref_3 = stan(stancode1, iter = 10000, data = standata_ref_3)

# Check
print(fit_ref_1, pars = c("LInf", "tZero", "k", "sigma" ))
print(fit_ref_2, pars = c("LInf", "tZero", "k", "sigma" ))
print(fit_ref_3, pars = c("LInf", "tZero", "k", "sigma" ))

#LOO
#All model into list for convenience when doing repeated operations
fits <- list(mod1=fit_ref_1, mod2 = fit_ref_2, mod3 = fit_ref_3)

#Loo object for each model
loos <- lapply(fits, loo, pars = "log_lik")
loos$mod1
print(loo_compare(loos), simplify = F)

looics = sapply(loos, function(x) x$estimates['looic', 'Estimate'])
delta_looic = looics - min(looics)
wi = exp(-0.5*delta_looic) / sum(exp(-0.5*delta_looic))
round(rbind(looic = looics, dlooic = delta_looic, weight = wi), 2)

# Save data
save(fit_ref_1, fit_ref_2, fit_ref_3, loos, file="Data/LOO_compare.RData")
```

```{r multimodel eval, include=FALSE}
load("Data/LOO_compare.RData")

#eval
pairs(fit_ref_1, pars = c("LInf", "k", "tZero", "sigma"))
pairs(fit_ref_2, pars = c("LInf", "k", "tZero", "sigma"))
pairs(fit_ref_3, pars = c("LInf", "k", "tZero", "sigma"))

samples_ref1 <- as.matrix(fit_ref_1, pars=c("LInf", "k", "tZero", "sigma"))
samples_ref2 <- as.matrix(fit_ref_2, pars=c("LInf", "k", "tZero", "sigma"))
samples_ref3 <- as.matrix(fit_ref_3, pars=c("LInf", "k", "tZero", "sigma"))

mcmc_combo(samples_ref1, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))
mcmc_combo(samples_ref2, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))
mcmc_combo(samples_ref3, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))

```

```{r Compare LOO scores table, include=FALSE, eval=FALSE}
rm(list = ls())

load("Data/LOO_compare.RData")

loos$mod1
print(loo_compare(loos), simplify = F)

looics = sapply(loos, function(x) x$estimates['looic', 'Estimate'])
delta_looic = looics - min(looics)
wi = exp(-0.5*delta_looic) / sum(exp(-0.5*delta_looic))
Loo <- as.data.frame(round(rbind(looic = looics, dlooic = delta_looic, weight = wi), 2))

Loo <- Loo%>%add_rownames()

Table <- Loo %>% flextable()%>%set_header_labels(rowname="", 
                                                 mod1="Model 1", 
                                                 mod2="Model 2",
                                                 mod3="Model 3")
save_as_docx(Table, path = "Tables/Loocompare.docx")
```

```{r growth models, include=FALSE}
# Script to fit VB growth curve with chosen prior structure to age data sets

rm(list = ls())

# load data
pikedata <- read.delim("Data/Pike_ages_all_with_TL_backcalulated.txt", header = T, stringsAsFactors = F)

priors <- read.delim("Data/Priors_pike.csv", sep = ";", header = T, stringsAsFactors = F)

# Transform TL mm to TL cm
pikedata$age_oto <- round(rowMeans(pikedata[,c("age_otoT", "age_otoK")]),0)
pikedata$age_scale <- round(rowMeans(pikedata[,c("age_scaleT", "age_scaleK")]),0)
pikedata <- pikedata %>% filter(area != "KD")

# Remove 0

pikedata[pikedata$age_scale == 0,]$age_scale <- 1

# Cleanup
growthdata <- pikedata %>%
  transmute(id = id,
            sex = sex,
            weight = weight,
            TL = TL/10,
            L = Length_LI/10,
            date = date,
            area = area,
            age_ref = age_ref,
            age_oto = age_oto,
            age_scale = age_scale)

# Write data lists for stan
# Reference age
standata_ref = list(
  Length = growthdata$L,
  Age = growthdata$age_ref,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/10,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

# Otolith age
standata_oto = list(
  Length = growthdata$L,
  Age = growthdata$age_oto,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/10,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

# Scale age
standata_scale = list(
  Length = growthdata$L,
  Age = growthdata$age_scale,
  N = nrow(growthdata),
  linf_mean = 150, #alt: mean^2/variance & variance/mean
  linf_var = 150/10,
  t0_mean = mean(priors$to),
  t0_var = sd(priors$to)^2,
  k_prior = 1,
  n_groupmax = as.integer(max(length(growthdata$id)))
)

# Modeling
stancode1 <- "Stan/Simple_VBGF_TZero.stan"

fit_ref = stan(stancode1, iter = 10000, data = standata_ref)
fit_oto = stan(stancode1, iter = 10000, data = standata_oto)
fit_scale = stan(stancode1, iter = 10000, data = standata_scale)

# check
print(fit_ref, pars = c("LInf", "tZero", "k", "sigma" ))
print(fit_oto, pars = c("LInf", "tZero", "k", "sigma" ))
print(fit_scale, pars = c("LInf", "tZero", "k", "sigma" ))

#Evaluation
pairs(fit_ref, pars = c("LInf", "k", "tZero", "sigma"))
pairs(fit_oto, pars = c("LInf", "k", "tZero", "sigma"))
pairs(fit_scale, pars = c("LInf", "k", "tZero", "sigma"))

samples_ref <- as.matrix(fit_ref, pars=c("LInf", "k", "tZero", "sigma"))
samples_oto <- as.matrix(fit_oto, pars=c("LInf", "k", "tZero", "sigma"))
samples_scale <- as.matrix(fit_scale, pars=c("LInf", "k", "tZero", "sigma"))

mcmc_combo(samples_ref, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))
mcmc_combo(samples_oto, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))
mcmc_combo(samples_scale, c("hist", "trace"), pars = c("LInf", "k", "tZero", "sigma"))

save(growthdata, fit_ref, fit_oto, fit_scale, samples_ref, samples_oto, samples_scale, file="Data/fit.RData")
```

```{r Inference, include=FALSE}
# Code to compare parameter estimates between aging structures

rm(list = ls())

load("Data/fit.RData")

#Transform LINf to array
sample_LInf1 <- as.array(fit_ref, pars = c("LInf"))
sample_LInf2 <- as.array(fit_oto, pars = c("LInf"))
sample_LInf3 <- as.array(fit_scale, pars = c("LInf"))

#Transform k to array
sample_k1 <- as.array(fit_ref, pars = c("k"))
sample_k2 <- as.array(fit_oto, pars = c("k"))
sample_k3 <- as.array(fit_scale, pars = c("k"))

# Transform t0 to array
sample_tzero1 <- as.array(fit_ref, pars = c("tZero"))
sample_tzero2 <- as.array(fit_oto, pars = c("tZero"))
sample_tzero3 <- as.array(fit_scale, pars = c("tZero"))

#Transform sigma (error term) to array
sample_sigma1 <- as.array(fit_ref, pars = c("sigma"))
sample_sigma2 <- as.array(fit_oto, pars = c("sigma"))
sample_sigma3 <- as.array(fit_scale, pars = c("sigma"))

# Compare estimates
#LInf
bayesplot_grid((mcmc_intervals(sample_LInf1)), (mcmc_intervals(sample_LInf2)),(mcmc_intervals(sample_LInf3)), xlim = c(80, 150), 
               titles = c("Reference", "Otoliths", "Scales"))

#k
bayesplot_grid((mcmc_intervals(sample_k1)), (mcmc_intervals(sample_k2)),(mcmc_intervals(sample_k3)), xlim = c(.1,.6), 
               titles = c("Reference", "Otoliths", "Scales"))

#t0
bayesplot_grid((mcmc_intervals(sample_tzero1)), (mcmc_intervals(sample_tzero2)),(mcmc_intervals(sample_tzero3)), xlim = c(0,-1), 
               titles = c("Reference", "Otoliths", "Scales"))

#sigma
bayesplot_grid((mcmc_intervals(sample_sigma1)), (mcmc_intervals(sample_sigma2)),(mcmc_intervals(sample_sigma3)), xlim = c(10,20), 
               titles = c("Reference", "Otoliths", "Scales"))

#area plots are a bit more informative
#LInf
bayesplot_grid(mcmc_areas(sample_LInf1, prob = 0.8, prob_outer = 0.90, point_est = "median"),
               mcmc_areas(sample_LInf2, prob = 0.8, prob_outer = 0.90, point_est = "median"),
               mcmc_areas(sample_LInf3, prob = 0.8, prob_outer = 0.90, point_est = "median"),
               xlim = c(80, 150))

#k
bayesplot_grid(mcmc_areas(sample_k1, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_k2, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_k3, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               xlim = c(.1, .6))

#t0
bayesplot_grid(mcmc_areas(sample_tzero1, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_tzero2, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_tzero3, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               xlim = c(-1, 0))

#sigma
bayesplot_grid(mcmc_areas(sample_sigma1, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_sigma2, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               mcmc_areas(sample_sigma3, prob = 0.8, prob_outer = 0.99, point_est = "median"),
               xlim = c(0, 20))
```

```{r extract prediction, include=FALSE}
# Script to extract Length-at-age predictions from growth models for later plotting
rm(list = ls())

#load data
load("Data/fit.RData")

# Prediction function

LTpredict<- function(pars, Age){
  pars[1]*(1-exp(-pars[2]*(Age-pars[3])))
}

Pred_ref <- t(apply(samples_ref[, c(1, 2, 3)], 1, LTpredict, Age = 0:15))
Pred_oto <- t(apply(samples_oto[, c(1, 2, 3)], 1, LTpredict, Age = 0:15))
Pred_scale <- t(apply(samples_scale[, c(1, 2, 3)], 1, LTpredict, Age = 0:15))

Quantile1 <- data.frame(t(apply(Pred_ref, 2, quantile, c(0.5, 0.05, 0.95))))
colnames(Quantile1) <- c("median", "lower", "upper")
Quantile1$age <- c(0:15)


Quantile2 <- data.frame(t(apply(Pred_oto, 2, quantile, c(0.5, 0.05, 0.95))))
colnames(Quantile2) <- c("median", "lower", "upper")
Quantile2$age <- c(0:15)

Quantile3 <- data.frame(t(apply(Pred_scale, 2, quantile, c(0.5, 0.05, 0.95))))
colnames(Quantile3) <- c("median", "lower", "upper")
Quantile3$age <- c(0:15)

# Save data object
save(fit_ref, fit_oto, fit_scale, samples_ref, samples_oto, samples_scale, Quantile1, Quantile2, Quantile3, growthdata, file="Data/Growthmodel.RData")
```

```{r Figure 6 Growthplots, echo=FALSE, fig.height=3, fig.width=9, dpi=600}

rm(list = ls())

# Load data
load("Data/Growthmodel.RData")

# Reference curve
Curve_ref <- ggplot() + xlab("Age (years)") + ylab("Total length (cm)") +
  geom_ribbon(data = Quantile1, aes(x = age, ymin = lower, ymax = upper), 
              fill = "#1B9E77", alpha = 0.2)+
  geom_line(data = Quantile1, aes(x = age, y = median), color = "#1B9E77", size = 1.2)+
  geom_point(data = growthdata, aes(x = age_ref, y = L), color = "black")+
  annotate("text", x = 7, y = 50, label = "L[infinity]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 50, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 50, label = paste(round(mean(samples_ref[,1]),2), "cm"), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 30, label = "k", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 30, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 30, label = round(mean(samples_ref[,2]),2), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 10, label = "t[0]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 10, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 10, label = paste(round(mean(samples_ref[,3]),2), "yr"), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  scale_x_continuous(expand = c(0, 0), limits = c(0, 16), breaks = c(1:15), 
                     labels = c("1","","3","","5","","7","","9","","11","","13","","15"))+ 
  scale_y_continuous(expand = c(0, 0), limits = c(0, 140), 
                     breaks = c(0,15,30,45,60,75,90,105,120),
                     labels = c("0","","30","","60","","90","","120"))+
  theme(axis.line = element_line(size = 1, colour = "black", linetype = 1),
        axis.ticks = element_line(size = 1, colour = "black"),
        axis.text = element_text(size = 15, colour = "black"),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        panel.background = element_blank(),
        #panel.grid.major = element_line(color = "grey", linetype = 3, size = .2),
        plot.title = element_text(size = 15, vjust = -5, hjust = 0.1))

# Otolith curve
Curve_oto <- ggplot() + xlab("Age (years)") + ylab("Total length (cm)") +
  geom_ribbon(data = Quantile2, aes(x = age, ymin = lower, ymax = upper), fill = "#D95F02", alpha = 0.2)+
  geom_line(data = Quantile2, aes(x = age, y = median), color = "#D95F02", size = 1.2)+
  geom_point(data = growthdata, aes(x = age_oto, y = L), color = "black")+
  geom_ribbon(data = Quantile1, aes(x = age, ymin = lower, ymax = upper), fill = "#1B9E77", alpha = 0.2)+
  geom_line(data = Quantile1, aes(x = age, y = median), color = "#1B9E77", size = 1.2)+
  #geom_point(data = pikedata, aes(x = age_comb, y = length_comb), color = "#1B9E77")+
  annotate("text", x = 7, y = 50, label = "L[infinity]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 50, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 50, label = paste(round(mean(samples_oto[,1]),2), "cm"), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 30, label = "k", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 30, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 30, label = round(mean(samples_oto[,2]),2), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 10, label = "t[0]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 10, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 10, label = paste(round(mean(samples_oto[,3]),2), "yr"), parse = F, 
           hjust = 0, color = "black", size = 4.5)+
  scale_x_continuous(expand = c(0, 0), limits = c(0, 16), breaks = c(1:15), 
                     labels = c("1","","3","","5","","7","","9","","11","","13","","15"))+ 
  scale_y_continuous(expand = c(0, 0), limits = c(0, 140), breaks = c(0,15,30,45,60,75,90,105,120),
                     labels = c("0","","30","","60","","90","","120"))+
  theme(axis.line = element_line(size = 1, colour = "black", linetype = 1),
        axis.ticks = element_line(size = 1, colour = "black"),
        axis.text = element_text(size = 15, colour = "black"),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        panel.background = element_blank(),
        #panel.grid.major = element_line(color = "grey", linetype = 3, size = .2),
        plot.title = element_text(size = 15, vjust = -5, hjust = 0.1))

# Scale curve-------------------------------------------------------------------------------
Curve_scale <- ggplot() + xlab("Age (years)") + ylab("Total length (cm)") +
  geom_ribbon(data = Quantile3, aes(x = age, ymin = lower, ymax = upper), fill = "#D95F02", alpha = 0.2)+
  geom_line(data = Quantile3, aes(x = age, y = median), color = "#D95F02", size = 1.2)+
  geom_point(data = growthdata, aes(x = age_scale, y = L), color = "black")+
  geom_ribbon(data = Quantile1, aes(x = age, ymin = lower, ymax = upper), fill = "#1B9E77", alpha = 0.2)+
  geom_line(data = Quantile1, aes(x = age, y = median), color = "#1B9E77", size = 1.2)+
  #geom_point(data = pikedata, aes(x = age_comb, y = length_comb), color = "#1B9E77")+
  annotate("text", x = 7, y = 50, label = "L[infinity]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 50, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 50, label = paste(round(mean(samples_scale[,1]),2), "cm"), parse = F, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 30, label = "k", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 30, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 30, label = round(mean(samples_scale[,2]),2), parse = F, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 7, y = 10, label = "t[0]", parse = T, hjust = 0, color = "black", size = 4.5)+
  annotate("text", x = 9, y = 10, label = "=", parse = F, hjust = .5, color = "black", size = 4.5)+
  annotate("text", x = 10, y = 10, label = paste(round(mean(samples_scale[,3]),2), "yr"), parse = F, hjust = 0, color = "black", size = 4.5)+
  scale_x_continuous(expand = c(0, 0), limits = c(0, 16), breaks = c(1:15), 
                     labels = c("1","","3","","5","","7","","9","","11","","13","","15"))+ 
  scale_y_continuous(expand = c(0, 0), limits = c(0, 140), breaks = c(0,15,30,45,60,75,90,105,120),
                     labels = c("0","","30","","60","","90","","120"))+
  theme(axis.line = element_line(size = 1, colour = "black", linetype = 1),
        axis.ticks = element_line(size = 1, colour = "black"),
        axis.text = element_text(size = 15, colour = "black"),
        axis.title.x = element_text(size = 15, face = "bold"),
        axis.title.y = element_text(size = 15, face = "bold"),
        panel.background = element_blank(),
        #panel.grid.major = element_line(color = "grey", linetype = 3, size = .2),
        plot.title = element_text(size = 15, vjust = -5, hjust = 0.1))

Curves <- ggarrange(Curve_ref, Curve_oto, Curve_scale, ncol = 3, nrow = 1, 
                    labels = c("A)", "B)", "C)"), label.x = 0, font.label = list(size = 15))
Curves
```

```{r Table 2 growthtable, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
# Script to concatenate growth data into table

rm(list = ls())

#load data
load("Data/Growthmodel.RData")

CI1LInf <- quantile(extract(fit_ref, pars = "LInf")[[1]], probs = c(0.05, 0.95))
CI2LInf <- quantile(extract(fit_oto, pars = "LInf")[[1]], probs = c(0.05, 0.95))
CI3LInf <- quantile(extract(fit_scale, pars = "LInf")[[1]], probs = c(0.05, 0.95))

CIsLInf <- rbind(CI1LInf, CI2LInf, CI3LInf)

SDsLInf <- CIsLInf[,2]-CIsLInf[,1]

CI1k <- quantile(extract(fit_ref, pars = "k")[[1]], probs = c(0.05, 0.95))
CI2k <- quantile(extract(fit_oto, pars = "k")[[1]], probs = c(0.05, 0.95))
CI3k <- quantile(extract(fit_scale, pars = "k")[[1]], probs = c(0.05, 0.95))

CIsk <- rbind(CI1k, CI2k, CI3k)

SDsk <- CIsk[,2]-CIsk[,1]

CI1tZero <- quantile(extract(fit_ref, pars = "tZero")[[1]], probs = c(0.05, 0.95))
CI2tZero <- quantile(extract(fit_oto, pars = "tZero")[[1]], probs = c(0.05, 0.95))
CI3tZero <- quantile(extract(fit_scale, pars = "tZero")[[1]], probs = c(0.05, 0.95))

CIstZero <- rbind(CI1tZero, CI2tZero, CI3tZero)

SDstZero <- CIstZero[,2]-CIstZero[,1]

Overview <- rbind(c(mean(samples_ref[,c(1)]), mean(samples_ref[,c(2)]), mean(samples_ref[,c(3)])),
                  c(mean(samples_oto[,c(1)]), mean(samples_oto[,c(2)]), mean(samples_oto[,c(3)])),
                  c(mean(samples_scale[,c(1)]), mean(samples_scale[,c(2)]), mean(samples_scale[,c(3)])))
                  

Overview <- data.frame(Overview)
Overview$sample <- c("Corroborated age", "Otolith age estimate", "Scale age estimate")
Overview$N <- 86

Overview$LInf <- paste(round(Overview$X1,1), "\u00B1", .5*(round(SDsLInf, 1)))
Overview$k <- paste(round(Overview$X2,2), "\u00B1", .5*(round(SDsk, 2)))
Overview$tZero <- paste(round(Overview$X3,1), "\u00B1", .5*(round(SDstZero, 1)))



Overviewtable <- flextable(Overview, col_keys = c("sample", "N", "LInf", "k", "tZero"))%>%
  fontsize(part = "header", size = 10)%>%
  bold(part = "header")%>%
  set_header_labels(sample = "Sample", LInf = "L \u221E [cm]", 
                                   k = "Body growth coefficient k", tZero = "Age at size 0 [yr]", N = "N")%>%
  set_table_properties(width = 0.99, layout = "autofit")%>%
  theme_vanilla()%>%
  set_caption("Summary of VBGF paramteters from different aging methods")

Overviewtable
```

## 3.5. Fisheries management reference points and optimal minimum-length limit
**Credit for the code for this chapter goes to my coauthor, Dr. Elias Ehrlich**
```{r model parameters, include=FALSE}
####################################
# Parameters - for Age Pike Model
# Created by: Elias Ehrlich
####################################
############
# Parameters
############
Bodden_area = 125200 #according to Rob van Gemerts' data in handover folder #126560 #170000 # [ha] 

a_max = 15                # Maximum age [years]
#M_min = 0.15              # Minimum adult natural mortality rate [year^-1]
M_min = 0.25              # Minimum adult natural mortality rate [year^-1]
theta = 0.5               # Lorenzen size-dependent mortality power (0-1.2)
#theta = 1.0               # Lorenzen size-dependent mortality power (0-1.2)

alpha_w = 0.0045          # Length-weight scaling constant
beta_w = 3.107            # Allometric parameter

l_mat = 375               # Length-at-maturation [mm]
alpha_f = 9.8             # Fecundity-weight scaling constant
beta_f = 1.12             # Power parameter relating fecundity to weight

R0 = 1.0*10^6             # Average total age-1 recruitment in the unfished stock []
SexRatioRecruits = 0.5    # females/(females+males)
CR = 6.1                  # Compensation ratio (paper: Goodyear 1980) []

#lmin_c = 375              # Minimum length at which vulnverable to capture [mm] 
lmin_c = 400              # Minimum length at which vulnverable to capture [mm] 
lmax_c = 1500             # Maximum length at which vulnerable to capture [mm]
#lmin_r = 375              # Minimum length at which vulnverable to capture [mm] 
lmin_r = 500              # Minimum length vulnerable to harvest [mm]
lmax_r = 1500             # Maximum length vulnerable to harvest [mm]

l_troph = 1000            # Minimum total length of a trophy fish [mm]

#F_mort = 0.1              # Instantaneous fishing mortality on individuals with selectivity of 1 [year^-1] (current situation)
F_mort = 0.2              # Instantaneous fishing mortality on individuals with selectivity of 1 [year^-1] (current situation)
d = 0.078                 # Discard mortality []; e.g. f_h=0.1 --> 10 % of released fish die 

# Growth parameters based on 3 different aging methods using scales, otoliths or the corroborated age, respectively (=3 values for each parameter)
measure_L8 = c(1236, 1010, 986.0)            # Measured mean asymptotic length L_8 (van Bertalanffy growth function VBGF) [mm] 
measure_k = c(0.17, 0.28, 0.28)              # Measured VBGF growth coefficient k [year^-1] for scale, otolith and corroborated age, respectively
measure_t0 = c(-0.4, -0.4, -0.4)             # Measured theoretical age at length of 0 t_0 [years] for scale, otolith and corroborated age, respectively
sd_L8 = c(198, 85.5, 109.5)                  # Standard deviation of L_8 [mm] of measurement for scale, otolith and corroborated age, respectively
sd_k = c(0.05, 0.055, 0.08)                  # Standard deviation of k [year^-1] of measurement for scale, otolith and corroborated age, respectively
sd_t0 = c(0.15, 0.15, 0.15)                  # Standard deviation of t_0 [years] of measurement for scale, otolith and corroborated age, respectively

CI_5_L8 = c(1055.5, 931.7, 889.2)            # 5 % confidence level for L_8 estimates
CI_95_L8 = c(1451.6, 1102.8, 1108.5)         # 95 % confidence level for L_8 estimates
CI_5_k = c(0.13, 0.22, 0.21)                 # 5 % confidence level for k estimates
CI_95_k = c(0.22, 0.34, 0.37)                # 95 % confidence level for k estimates
CI_5_t0 = c(-0.56, -0.55, -0.58)             # 5 % confidence level for t_0 estimatees
CI_95_t0 = c(-0.25, -0.25, -0.28)            # 95 % confidence level for t_0 estimates

cv = 0.13                                   # Coefficient of variation in VBGF among individuals

# Random seed number for reproducibility of results
RandomSeedNr = 126
```

```{r pike age model & figure 7, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
#############################################################################################################
# Pike model: Effect of different ageing methods on fishery reference points and optimal minimum length limit  
# Code author: Elias Ehrlch           
#############################################################################################################

setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to source file (for using RStudio)

#############################
# Load Packages and functions
#############################
library(matrixStats)
library(reshape2)
library(ggplot2)
library(patchwork)

#########
# Setting
#########
SAVE = 0                  # Set to 1 to save png plot and to 0 if not

##############
# Loading Data
##############
#source("Data/AgePikeModel_Parameters.R") # Import parameters

path = "Data/SimData/FishRefPoints/"
F_mort_vec = readRDS(file=paste0(path, "F_mort.rds"))               # Scenarios of instantaneous fishing mortalities
N_vec_rep = readRDS(file=paste0(path, "N_F_mort.rds"))              # Temporal average total stock size
HarvN_vec_rep = readRDS(file=paste0(path, "HarvN_F_mort.rds"))      # Temporal average harvestable stock size
VulnN_vec_rep = readRDS(file=paste0(path, "VulnN_F_mort.rds"))      # Temporal average stock size vulnerable to catch
TrophyN_vec_rep = readRDS(file=paste0(path, "TrophyN_F_mort.rds"))  # Temporal average trophy stock size
AmountTrophy_vec_rep = readRDS(file=paste0(path, "AmountTrophy_F_mort.rds"))  # Temporal average amount of trophy fish in population
B_vec_rep = readRDS(file=paste0(path, "B_F_mort.rds"))              # Temporal average total biomass
Y_vec_rep = readRDS(file=paste0(path, "Y_F_mort.rds"))              # Temporal average yield
YN_vec_rep = readRDS(file=paste0(path, "YN_F_mort.rds"))            # Temporal average yield

n_meth = dim(N_vec_rep) [3]                 # Number of different aging methods
n_rep = dim(N_vec_rep) [2]                  # Number of random samples of growth parameters per aging method
n = dim(N_vec_rep) [1]                      # Number of scenarios of F

########################################
# Calculating fisheries reference points
########################################
# Fishery reference points for each random sample of growth parameters for the n_meth=3 aging methods
MSY_rep = matrix(NA, n_rep, n_meth)
F_MSY_rep = matrix(NA, n_rep, n_meth)
B_MSY_rep = matrix(NA, n_rep, n_meth)
N_MSY_rep = matrix(NA, n_rep, n_meth)
HarvN_MSY_rep = matrix(NA, n_rep, n_meth)
VulnN_MSY_rep = matrix(NA, n_rep, n_meth)
TrophyN_MSY_rep = matrix(NA, n_rep, n_meth)

YNmax_rep = matrix(NA, n_rep, n_meth) 

for (h in 1:n_meth){
  MSY_rep[,h] = apply(Y_vec_rep[,,h], 2, max)                 # MSY (=highest temporal mean yield over all scenarios) for each growth parameter sample
  Index_max = apply(Y_vec_rep[,,h], 2, which.max)             # Index of MSY in output metrix Y_vec_rep[,,h] for each growth parameter sample
  F_MSY_rep[,h] = F_mort_vec[Index_max]                       # F_MSY for each growth parameter sample
  for (j in 1:n_rep){
    B_MSY_rep[j,h] = B_vec_rep[Index_max[j],j,h]              # B_MSY for each growth parameter sample
    N_MSY_rep[j,h] = N_vec_rep[Index_max[j],j,h]              # N_MSY for each growth parameter sample
    HarvN_MSY_rep[j,h] = HarvN_vec_rep[Index_max[j],j,h]  
    VulnN_MSY_rep[j,h] = VulnN_vec_rep[Index_max[j],j,h]  
    TrophyN_MSY_rep[j,h] = TrophyN_vec_rep[Index_max[j],j,h]
  }
  YNmax_rep[,h] = apply(YN_vec_rep[,,h], 2, max)              # Maximum number of harvested fish for each growth parameter sample
}

########################################
# Box plots for fishery reference points
########################################
F_MSY_data = data.frame(F_MSY_rep)
MSY_data = data.frame(MSY_rep)
B_MSY_data = data.frame(B_MSY_rep)
Methods = c("Scales", "Otoliths", "Corroborated")
colnames(F_MSY_data) = Methods
colnames(MSY_data) = Methods
colnames(B_MSY_data) = Methods

FishRefPoints = data.frame(matrix(NA, n_rep*n_meth, 4))
colnames(FishRefPoints) = c("F_MSY", "MSY", "B_MSY", "Method")
FishRefPoints$F_MSY = melt(F_MSY_data)$value
FishRefPoints$MSY = melt(MSY_data)$value
FishRefPoints$B_MSY = melt(B_MSY_data)$value
FishRefPoints$Method = melt(F_MSY_data)$variable

Col_data = c("#E69F00", "#56B4E9", "#999999")
options(scipen=5)                             # Avoiding notation of numbers as a power of ten on the axes (i.e. no 'e-5') 

p1 <- ggplot(FishRefPoints, aes(x=Method, y=F_MSY, fill=Method)) +
  geom_boxplot(outlier.shape = NA) + #--> outliers not plotted
  xlab("Aging method") +
  ylab(expression(""~ F[MSY] ~" ["~ year^{-1} ~"]")) +
  scale_fill_manual(values=Col_data) +
  theme_bw() +
  coord_cartesian(ylim = c(0.17, 0.28)) +
  scale_y_continuous(breaks=seq(0.18, 0.28, 0.02)) +
  theme(legend.position = "none")
p2 <- ggplot(FishRefPoints, aes(x=Method, y=MSY*1e3/Bodden_area, fill=Method)) +
  geom_boxplot(outlier.shape = NA) +
  xlab("Aging method") +
  ylab(expression("MSY [kg "~ ha^-1 ~ year^{-1} ~"]")) +
  scale_fill_manual(values=Col_data) +
  coord_cartesian(ylim = c(0, 8)) +
  scale_y_continuous(breaks=seq(0, 10, 2)) +
  theme_bw() +
  theme(legend.position = "none")
p3 <- ggplot(FishRefPoints, aes(x=Method, y=B_MSY*1e3/Bodden_area, fill=Method)) +
  geom_boxplot(outlier.shape = NA) +
  xlab("Aging method") +
  ylab(expression(""~ B[MSY] ~" [kg" ~ ha^-1 ~ "]")) +
  scale_fill_manual(values=Col_data) +
  coord_cartesian(ylim = c(0, 50)) +
  theme_bw() +
  theme(legend.position = "none")

##############
# Loading Data
##############
path = "Data/SimData/MinSizeLim/"
lmin_r_vec = readRDS(file=paste0(path, "MinSizeLim.rds"))               # Scenarios of instantaneous fishing mortalities
N_vec_rep = readRDS(file=paste0(path, "N_MinSizeLim.rds"))              # Temporal average total stock size
HarvN_vec_rep = readRDS(file=paste0(path, "HarvN_MinSizeLim.rds"))      # Temporal average harvestable stock size
VulnN_vec_rep = readRDS(file=paste0(path, "VulnN_MinSizeLim.rds"))      # Temporal average stock size vulnerable to catch
TrophyN_vec_rep = readRDS(file=paste0(path, "TrophyN_MinSizeLim.rds"))  # Temporal average trophy stock size
B_vec_rep = readRDS(file=paste0(path, "B_MinSizeLim.rds"))              # Temporal average total biomass
Y_vec_rep = readRDS(file=paste0(path, "Y_MinSizeLim.rds"))              # Temporal average yield
YN_vec_rep = readRDS(file=paste0(path, "YN_MinSizeLim.rds"))            # Temporal average numeric yield
Utility_vec_rep = readRDS(file=paste0(path, "Utility_MinSizeLim.rds"))  # Temporal average yield

n_meth = dim(N_vec_rep) [3]                 # Number of different aging methods
n_rep = dim(N_vec_rep) [2]                  # Number of random samples of growth parameters per aging method
n = dim(N_vec_rep) [1]                      # Number of scenarios of minimum size limits

##########################################
# Identifying optimal minimum length limit
##########################################
MaxUtil_rep = matrix(NA, n_rep, n_meth)
MinLL_MaxUtil_rep = matrix(NA, n_rep, n_meth)

for (h in 1:n_meth){
  MaxUtil_rep[,h] = apply(Utility_vec_rep[,,h], 2, max)       # Maximum utility for each growth parameter sample
  Index_max = apply(Utility_vec_rep[,,h], 2, which.max)       # Index of Maximum utility in output metrix Utility_vec_rep[,,h] for each growth parameter sample
  MinLL_MaxUtil_rep[,h] = lmin_r_vec[Index_max]               # Optimal minimum length limit for each growth parameter sample
}

# Mean and sd of maximum utility and optimal minimum length limit from all growth parameter samples 
MaxUtil_mean_sd = rbind( colMeans(MaxUtil_rep), colSds(MaxUtil_rep) )
MinLL_MaxUtil_mean_sd = rbind( colMeans(MinLL_MaxUtil_rep), colSds(MinLL_MaxUtil_rep) )

#########################################
# Box plots for optimal min. length limit
#########################################
OptMinLL_data = data.frame(MinLL_MaxUtil_rep)
Methods = c("Scales", "Otoliths", "Corroborated")
colnames(OptMinLL_data) = Methods

OptSizeLim = data.frame(matrix(NA, n_rep*n_meth, 2))
colnames(OptSizeLim) = c("OptMinLL", "Method")
OptSizeLim$OptMinLL = melt(OptMinLL_data)$value
OptSizeLim$Method = melt(OptMinLL_data)$variable

p4 <- ggplot(OptSizeLim, aes(x=Method, y=OptMinLL/10, fill=Method)) +
  geom_boxplot(outlier.shape = NA) + # geom_boxplot(outlier.shape = NA) #--> outliers not plotted
  xlab("Aging method") +
  ylab(expression("Optimal min. length limit [cm]")) +
  scale_fill_manual(values=Col_data) +
  theme_bw() +
  #coord_cartesian(ylim = c(0.14, 0.24)) +
  theme(legend.position = "none")

if(SAVE){png("Plots/FishRefPoints_OptMinLL_Boxplots.png", width = 4000, height = 3400, res=600)}

(p1 + p2) /
(p3 + p4) + plot_annotation(tag_levels = "a")

if(SAVE){dev.off()}

aggregate(FishRefPoints[, 1:3], list(FishRefPoints$Method), median)
aggregate(FishRefPoints[, 1:3], list(FishRefPoints$Method), mean)
aggregate(OptSizeLim[, 1], list(OptSizeLim$Method), median)
aggregate(OptSizeLim[, 1], list(OptSizeLim$Method), mean)
```

```{r pike age model & figure 8, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE}
####################################################################################
# Pike model: Effect of different age reading methods on fishery reference points  
# Code author: Elias Ehrlch           
####################################################################################

setwd(dirname(rstudioapi::getActiveDocumentContext()$path)) # set working directory to source file (for using RStudio)

#############################
# Load Packages and functions
#############################
library(matrixStats)
library(reshape2)
library(ggplot2)
library(patchwork)

#########
# Setting
#########
SAVE = 0                  # Set to 1 to save png plot and to 0 if not

##############
# Loading Data
##############
#source("AgePikeModel_Parameters.R") # Import parameters

path = "Data/SimData/FishRefPoints/"
F_mort_vec = readRDS(file=paste0(path, "F_mort.rds"))               # Scenarios of instantaneous fishing mortalities
N_vec_rep = readRDS(file=paste0(path, "N_F_mort.rds"))              # Temporal average total stock size
HarvN_vec_rep = readRDS(file=paste0(path, "HarvN_F_mort.rds"))      # Temporal average harvestable stock size
VulnN_vec_rep = readRDS(file=paste0(path, "VulnN_F_mort.rds"))      # Temporal average stock size vulnerable to catch
TrophyN_vec_rep = readRDS(file=paste0(path, "TrophyN_F_mort.rds"))  # Temporal average trophy stock size
AmountTrophy_vec_rep = readRDS(file=paste0(path, "AmountTrophy_F_mort.rds"))  # Temporal average amount of trophy fish in population
B_vec_rep = readRDS(file=paste0(path, "B_F_mort.rds"))              # Temporal average total biomass
Y_vec_rep = readRDS(file=paste0(path, "Y_F_mort.rds"))              # Temporal average yield
YN_vec_rep = readRDS(file=paste0(path, "YN_F_mort.rds"))            # Temporal average yield

n_meth = dim(N_vec_rep) [3]                 # Number of different aging methods
n_rep = dim(N_vec_rep) [2]                  # Number of random samples of growth parameters per aging method
n = dim(N_vec_rep) [1]                      # Number of scenarios of F

########################################
# Calculating fisheries reference points
########################################
# Fishery reference points for each random sample of growth parameters for the n_meth=3 aging methods
MSY_rep = matrix(NA, n_rep, n_meth)
F_MSY_rep = matrix(NA, n_rep, n_meth)
B_MSY_rep = matrix(NA, n_rep, n_meth)
N_MSY_rep = matrix(NA, n_rep, n_meth)
HarvN_MSY_rep = matrix(NA, n_rep, n_meth)
VulnN_MSY_rep = matrix(NA, n_rep, n_meth)
TrophyN_MSY_rep = matrix(NA, n_rep, n_meth)

YNmax_rep = matrix(NA, n_rep, n_meth) 

# my.max <- function(x) ifelse( !all(is.na(x)), max(x, na.rm=T), NA) # if every (all) element in x is NA, then NA is returned, and the max otherwise

for (h in 1:n_meth){
  MSY_rep[,h] = apply(Y_vec_rep[,,h], 2, max)                 # MSY (=highest temporal mean yield over all scenarios) for each growth parameter sample
  Index_max = apply(Y_vec_rep[,,h], 2, which.max)             # Index of MSY in output metrix Y_vec_rep[,,h] for each growth parameter sample
  F_MSY_rep[,h] = F_mort_vec[Index_max]                       # F_MSY for each growth parameter sample
  for (j in 1:n_rep){
    B_MSY_rep[j,h] = B_vec_rep[Index_max[j],j,h]              # B_MSY for each growth parameter sample
    N_MSY_rep[j,h] = N_vec_rep[Index_max[j],j,h]              # N_MSY for each growth parameter sample
    HarvN_MSY_rep[j,h] = HarvN_vec_rep[Index_max[j],j,h]  
    VulnN_MSY_rep[j,h] = VulnN_vec_rep[Index_max[j],j,h]  
    TrophyN_MSY_rep[j,h] = TrophyN_vec_rep[Index_max[j],j,h]
  }
  YNmax_rep[,h] = apply(YN_vec_rep[,,h], 2, max)              # Maximum number of harvested fish for each growth parameter sample
}

#################################
# Plots of output metrices over F
#################################
# Function to provide 25% quantile, mean, and 75 % qantile
MeanIQR <- function(Data){
  c(round(mean(Data),4), round(quantile(Data, prob=.25),4), round(quantile(Data, prob=.75),4) )
}

N_mean_IQR = array(NA, dim=c(n, 3, n_meth))                      # Average stock size (Quantiles and mean for all growth parameter samples)
HarvN_mean_IQR = array(NA, dim=c(n, 3, n_meth))                  # Average harvestable stock size (Quantiles and mean for all growth parameter samples)
VulnN_mean_IQR = array(NA, dim=c(n, 3, n_meth))                  # Average stock size vulnerable to catch (Quantiles and mean for all growth parameter samples)
TrophyN_mean_IQR = array(NA, dim=c(n, 3, n_meth))                # Average trophy stock size (Quantiles and mean for all growth parameter samples)
AmountTrophy_mean_IQR = array(NA, dim=c(n, 3, n_meth))           # Average amount of trophy fish in population (Quantiles and mean for all growth parameter samples)
B_mean_IQR = array(NA, dim=c(n, 3, n_meth))                      # Average stock biomass (Quantiles and mean for all growth parameter samples)
Y_mean_IQR = array(NA, dim=c(n, 3, n_meth))                      # Average yield (Quantiles and mean for all growth parameter samples)
YN_mean_IQR = array(NA, dim=c(n, 3, n_meth))                     # Average numeric yield (Quantiles and mean for all growth parameter samples)

for(h in 1:n_meth){
  for(i in 1:n){
    N_mean_IQR[i,,h] = MeanIQR(N_vec_rep[i,,h])                   # Quantiles and mean of average stock size [ind.]
    HarvN_mean_IQR[i,,h] = MeanIQR(HarvN_vec_rep[i,,h])           # Quantiles and mean of average harvestable stock size [ind.]
    VulnN_mean_IQR[i,,h] = MeanIQR(VulnN_vec_rep[i,,h])           # Quantiles and mean of average harvestable stock size [ind.]
    TrophyN_mean_IQR[i,,h] = MeanIQR(TrophyN_vec_rep[i,,h])       # Quantiles and mean of average trophy stock size [ind.]
    AmountTrophy_mean_IQR[i,,h] = MeanIQR(AmountTrophy_vec_rep[i,,h])       # Quantiles and mean of average amount of trophy fish in population []
    B_mean_IQR[i,,h] = MeanIQR(B_vec_rep[i,,h])                   # Quantiles and mean of average stock biomass [t]
    Y_mean_IQR[i,,h] = MeanIQR(Y_vec_rep[i,,h])                   # Quantiles and mean of average yield [t year^-1]
    YN_mean_IQR[i,,h] = MeanIQR(YN_vec_rep[i,,h])                 # Quantiles and mean of average numeric yield [Ind. year^-1]
  }
}

# Plot settings
ggbg <- function() {                          # for background and grid color of plot
  points(0, 0, pch=16, cex=1e6, col="white")
  grid(col="gray95", lty=1)
}

fontsize_lab = 1.4
fontsize_axis = 1.2
linewidth = 2.0
pointsize = 1.5
Col_data = c("#E69F00", "#56B4E9", "grey35")
Col_IQR = adjustcolor(Col_data, alpha.f = 0.2)
AreaDensLine = c(NA, NA, 35)
AreaAngleLine = c(NA, NA, 90)
subplot_labels = c("a", "b", "c")

# Values and labels of plot axes for two different size limits (x-axis) and three different output metrices (y-axis), respectively
ScalingN = 1e5
Xlab = expression("Fishing mortality [" ~ year^{-1} ~"]")
Yax = c(parse(text="Y_mean_IQR*1e3/Bodden_area"), parse(text="B_mean_IQR*1e3/Bodden_area"), parse(text="AmountTrophy_mean_IQR"))
Ylab = c(expression("Yield [kg" ~ ha^-1 ~ year^{-1} ~ "]"), expression("Biomass [kg" ~ ha^-1 ~ "]"), expression("Amount of fish">="1m"))
#Y_F_MSY = c(parse(text="MSY"), parse(text="B_MSY"), parse(text="TrophyN_MSY"))

# Plotting function - plot output metrics 'Y' (= Yield, Biomass or Number of trophy fish)
Plot_func <- function(x, yax, F_MSY, Xlab, Ylab, panel, Col_data, Col_IQR, AreaDensLine, AreaAngleLine, linewidth, pointsize, fontsize_lab, fontsize_axis, subplot_label, LEGEND){
  # -> Scales - mean and IQR
  matplot(x, yax[,1,1], xlab=Xlab, ylab=Ylab, panel.first=panel, col=Col_data[1], type='l',
          lty=1, lwd=linewidth, cex.lab=fontsize_lab, cex.axis=fontsize_axis, ylim=c(0,max(yax)))
  polygon(c(x, rev(x)), c(yax[,3,1], rev(yax[,2,1])), col=Col_IQR[1], density = AreaDensLine[1], angle = AreaAngleLine[1], border=NA)
  # -> Otoliths - mean and IQR
  points(x, yax[,1,2], type='l',  lty=1, lwd=linewidth, col=Col_data[2])
  polygon(c(x,rev(x)),c(yax[,3,2],rev(yax[,2,2])),col=Col_IQR[2], density = AreaDensLine[2], angle = AreaAngleLine[2], border=NA)
  # -> Corroborated age - mean and IQR
  points(x, yax[,1,3], type='l',  lty=1, lwd=linewidth, col=Col_data[3])
  polygon(c(x,rev(x)),c(yax[,3,3],rev(yax[,2,3])),col=Col_IQR[3], density = AreaDensLine[3], angle = AreaAngleLine[3], border=NA)
  
  # for (nn in 1:3){
  #   segments(F_MSY[nn],0,F_MSY[nn],y_F_MSY[nn],col=Col_data[nn],lty=2)
  #   points(F_MSY[nn],y_F_MSY[nn],col=Col_data[nn],pch=16,cex=pointsize)         # adding reference point for (F_MSY, MSY)
  # }

  mtext(subplot_label, adj=-0.27, line=-0.1)
  
  if(LEGEND==T) { legend("topright",c("Scales", "Otoliths", "Corroborated"), lty=1, col=Col_data)}
}

# Plotting - min, mean and max of model output (if no cycles, all 3 appearing as one line)
if(SAVE){png("Plots/Curves_YieldBiomTrophy_vs_F.png", width = 6000, height = 1800, res=600)}
par(mfrow=c(1,3),mar=c(4,5,1,1)) #,bty="n")

for(pp in 1:length(Yax)){
  yax = eval(Yax[pp])
  if(pp == 2){LEGEND = T} else{LEGEND = F}
  Plot_func(F_mort_vec, yax, F_MSY[1,], Xlab, Ylab[pp], ggbg(), Col_data, Col_IQR, AreaDensLine, AreaAngleLine, linewidth, pointsize, fontsize_lab, fontsize_axis, subplot_labels[pp], LEGEND)
}

if(SAVE){dev.off()}
```
